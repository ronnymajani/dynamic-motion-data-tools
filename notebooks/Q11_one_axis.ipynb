{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow the notebook to access the parent directory so we can import the other modules\n",
    "# https://stackoverflow.com/a/35273613\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Folder Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_folder_path = os.path.join(\"..\", \"files\", \"dataset\")\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Split into *Test*, *Train/Valid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DataSet import DataSet\n",
    "dataset = DataSet()\n",
    "# dataset.load(dataset_folder_path, test_set_percentage=0.3333, validation_set_percentage=0.3333)\n",
    "dataset.load(dataset_folder_path, test_set_percentage=0, validation_set_percentage=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train_data))\n",
    "print(len(dataset.test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 50\n",
    "from utils.preprocessing import *\n",
    "from functools import partial\n",
    "dataset.apply(apply_mean_centering)\n",
    "dataset.apply(apply_unit_distance_normalization)\n",
    "#dataset.apply(partial(normalize_pressure_value, max_pressure_val=512))\n",
    "dataset.apply(partial(spline_interpolate_and_resample, num_samples=NUM_SAMPLES))\n",
    "dataset.expand(reverse_digit_sequence)\n",
    "# dataset.apply(lambda digit: convert_xy_to_derivative(digit, normalize=False))\n",
    "#dataset.apply(partial(convert_xy_to_derivative, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train_data))\n",
    "print(len(dataset.test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dataset, don't split, don't onehot encode, since we will perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 50, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig = np.array(dataset.train_data)\n",
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(dataset.train_labels)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X Axis Only:\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only X axis values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_orig[:, :, 0].reshape(X_train_orig.shape[0], X_train_orig.shape[1], 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## **Regularized Deep GRU**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/20\n",
      "4800/4800 [==============================] - 11s 2ms/step - loss: 2.1945 - categorical_accuracy: 0.1908 - val_loss: 2.0497 - val_categorical_accuracy: 0.2467\n",
      "Epoch 2/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.9984 - categorical_accuracy: 0.2775 - val_loss: 2.0123 - val_categorical_accuracy: 0.3117\n",
      "Epoch 3/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 2.0196 - categorical_accuracy: 0.2812 - val_loss: 1.9022 - val_categorical_accuracy: 0.3021\n",
      "Epoch 4/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.8495 - categorical_accuracy: 0.3427 - val_loss: 1.8314 - val_categorical_accuracy: 0.3496\n",
      "Epoch 5/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.5966 - categorical_accuracy: 0.4310 - val_loss: 1.6240 - val_categorical_accuracy: 0.4087\n",
      "Epoch 6/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.4289 - categorical_accuracy: 0.4896 - val_loss: 1.2964 - val_categorical_accuracy: 0.5663\n",
      "Epoch 7/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.1592 - categorical_accuracy: 0.5950 - val_loss: 1.0675 - val_categorical_accuracy: 0.6558\n",
      "Epoch 8/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.9364 - categorical_accuracy: 0.6746 - val_loss: 0.8917 - val_categorical_accuracy: 0.7271\n",
      "Epoch 9/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.6950 - categorical_accuracy: 0.7604 - val_loss: 0.9470 - val_categorical_accuracy: 0.7133\n",
      "Epoch 10/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.5656 - categorical_accuracy: 0.8117 - val_loss: 0.8254 - val_categorical_accuracy: 0.7600\n",
      "Epoch 11/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4745 - categorical_accuracy: 0.8406 - val_loss: 0.6682 - val_categorical_accuracy: 0.8142\n",
      "Epoch 12/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4336 - categorical_accuracy: 0.8556 - val_loss: 0.6004 - val_categorical_accuracy: 0.8375\n",
      "Epoch 13/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.3530 - categorical_accuracy: 0.8863 - val_loss: 0.5928 - val_categorical_accuracy: 0.8421\n",
      "Epoch 14/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2753 - categorical_accuracy: 0.9083 - val_loss: 0.6168 - val_categorical_accuracy: 0.8358\n",
      "Epoch 15/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2682 - categorical_accuracy: 0.9081 - val_loss: 0.5519 - val_categorical_accuracy: 0.8583\n",
      "Epoch 16/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2370 - categorical_accuracy: 0.9233 - val_loss: 0.6063 - val_categorical_accuracy: 0.8387\n",
      "Epoch 17/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.2052 - categorical_accuracy: 0.9263 - val_loss: 0.5563 - val_categorical_accuracy: 0.8538\n",
      "Epoch 18/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.1929 - categorical_accuracy: 0.9381 - val_loss: 0.5169 - val_categorical_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.1640 - categorical_accuracy: 0.9458 - val_loss: 0.5829 - val_categorical_accuracy: 0.8571\n",
      "Epoch 20/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.1998 - categorical_accuracy: 0.9306 - val_loss: 0.7320 - val_categorical_accuracy: 0.8246\n",
      "2400/2400 [==============================] - 2s 903us/step\n",
      "categorical_accuracy: 82.46%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/20\n",
      "4800/4800 [==============================] - 11s 2ms/step - loss: 2.1695 - categorical_accuracy: 0.1975 - val_loss: 2.0217 - val_categorical_accuracy: 0.2637\n",
      "Epoch 2/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.9559 - categorical_accuracy: 0.3002 - val_loss: 1.9477 - val_categorical_accuracy: 0.3362\n",
      "Epoch 3/20\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 1.8419 - categorical_accuracy: 0.3596 - val_loss: 1.6613 - val_categorical_accuracy: 0.4304\n",
      "Epoch 4/20\n",
      "3900/4800 [=======================>......] - ETA: 1s - loss: 1.7235 - categorical_accuracy: 0.4056"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-419054ae96d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARAM_NUM_EPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/Thesis/dynamic-motion-data-tools/utils/evaluation.py\u001b[0m in \u001b[0;36mcross_validate_model\u001b[0;34m(X, Y, model, n_folds, random_state)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# even though we are passing thevalidation set to the training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# it is not being used a swe disabled callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mmodel_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Thesis/dynamic-motion-data-tools/models/regularized_1024_gru.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, X_valid, Y_valid)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         }\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 40\n",
    "PARAM_BATCH_SIZE = 300\n",
    "\n",
    "from models.regularized_deep_gru import RegularizedDeepGRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = RegularizedDeepGRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## **Regularized 64 GRU**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 2s 517us/step - loss: 2.2622 - categorical_accuracy: 0.1519 - val_loss: 2.2352 - val_categorical_accuracy: 0.1608\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 2.1700 - categorical_accuracy: 0.1923 - val_loss: 2.1269 - val_categorical_accuracy: 0.2196\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 2.0426 - categorical_accuracy: 0.2567 - val_loss: 2.0748 - val_categorical_accuracy: 0.2696\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 1.9029 - categorical_accuracy: 0.3104 - val_loss: 1.7880 - val_categorical_accuracy: 0.3463\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 1.7525 - categorical_accuracy: 0.3577 - val_loss: 1.6450 - val_categorical_accuracy: 0.4021\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.6524 - categorical_accuracy: 0.4025 - val_loss: 1.5335 - val_categorical_accuracy: 0.4413\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 1.5096 - categorical_accuracy: 0.4702 - val_loss: 1.3869 - val_categorical_accuracy: 0.5083\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 1.3394 - categorical_accuracy: 0.5194 - val_loss: 1.2352 - val_categorical_accuracy: 0.5642\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.2177 - categorical_accuracy: 0.5794 - val_loss: 1.1334 - val_categorical_accuracy: 0.6217\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.1146 - categorical_accuracy: 0.5987 - val_loss: 1.0764 - val_categorical_accuracy: 0.6342\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 1.0174 - categorical_accuracy: 0.6508 - val_loss: 0.9954 - val_categorical_accuracy: 0.6742\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.9458 - categorical_accuracy: 0.6669 - val_loss: 0.9287 - val_categorical_accuracy: 0.6975\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.8866 - categorical_accuracy: 0.6852 - val_loss: 0.8782 - val_categorical_accuracy: 0.7083\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.8442 - categorical_accuracy: 0.7171 - val_loss: 0.8673 - val_categorical_accuracy: 0.7296\n",
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.7792 - categorical_accuracy: 0.7438 - val_loss: 0.8199 - val_categorical_accuracy: 0.7413\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.7477 - categorical_accuracy: 0.7477 - val_loss: 0.8444 - val_categorical_accuracy: 0.7304\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.6945 - categorical_accuracy: 0.7715 - val_loss: 0.7709 - val_categorical_accuracy: 0.7587\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.6742 - categorical_accuracy: 0.7735 - val_loss: 0.7493 - val_categorical_accuracy: 0.7654\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 275us/step - loss: 0.6229 - categorical_accuracy: 0.7996 - val_loss: 0.7395 - val_categorical_accuracy: 0.7708\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.6180 - categorical_accuracy: 0.7998 - val_loss: 0.7032 - val_categorical_accuracy: 0.7971\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.5694 - categorical_accuracy: 0.8165 - val_loss: 0.6720 - val_categorical_accuracy: 0.8008\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.5485 - categorical_accuracy: 0.8252 - val_loss: 0.6476 - val_categorical_accuracy: 0.8142\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.5243 - categorical_accuracy: 0.8415 - val_loss: 0.7295 - val_categorical_accuracy: 0.7854\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.5011 - categorical_accuracy: 0.8446 - val_loss: 0.6329 - val_categorical_accuracy: 0.8262\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.4787 - categorical_accuracy: 0.8525 - val_loss: 0.6429 - val_categorical_accuracy: 0.8204\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.4501 - categorical_accuracy: 0.8590 - val_loss: 0.6214 - val_categorical_accuracy: 0.8292\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.4274 - categorical_accuracy: 0.8706 - val_loss: 0.6048 - val_categorical_accuracy: 0.8308\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.4288 - categorical_accuracy: 0.8663 - val_loss: 0.6606 - val_categorical_accuracy: 0.8233\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4284 - categorical_accuracy: 0.8715 - val_loss: 0.6120 - val_categorical_accuracy: 0.8400\n",
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4054 - categorical_accuracy: 0.8771 - val_loss: 0.6114 - val_categorical_accuracy: 0.8358\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.3846 - categorical_accuracy: 0.8825 - val_loss: 0.6032 - val_categorical_accuracy: 0.8408\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3811 - categorical_accuracy: 0.8802 - val_loss: 0.6458 - val_categorical_accuracy: 0.8283\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3667 - categorical_accuracy: 0.8879 - val_loss: 0.6180 - val_categorical_accuracy: 0.8362\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.3739 - categorical_accuracy: 0.8810 - val_loss: 0.6273 - val_categorical_accuracy: 0.8400\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.3449 - categorical_accuracy: 0.8981 - val_loss: 0.6634 - val_categorical_accuracy: 0.8338\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3355 - categorical_accuracy: 0.8960 - val_loss: 0.6196 - val_categorical_accuracy: 0.8421\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.3153 - categorical_accuracy: 0.9044 - val_loss: 0.6587 - val_categorical_accuracy: 0.8413\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.3319 - categorical_accuracy: 0.8969 - val_loss: 0.6378 - val_categorical_accuracy: 0.8475\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3177 - categorical_accuracy: 0.9038 - val_loss: 0.6673 - val_categorical_accuracy: 0.8438\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.3120 - categorical_accuracy: 0.9006 - val_loss: 0.6246 - val_categorical_accuracy: 0.8500\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3033 - categorical_accuracy: 0.9092 - val_loss: 0.6073 - val_categorical_accuracy: 0.8558\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3129 - categorical_accuracy: 0.9079 - val_loss: 0.6151 - val_categorical_accuracy: 0.8525\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2877 - categorical_accuracy: 0.9140 - val_loss: 0.6421 - val_categorical_accuracy: 0.8417\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2880 - categorical_accuracy: 0.9115 - val_loss: 0.6580 - val_categorical_accuracy: 0.8408\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2897 - categorical_accuracy: 0.9088 - val_loss: 0.6013 - val_categorical_accuracy: 0.8513\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.2732 - categorical_accuracy: 0.9167 - val_loss: 0.6308 - val_categorical_accuracy: 0.8483\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2600 - categorical_accuracy: 0.9190 - val_loss: 0.6033 - val_categorical_accuracy: 0.8550\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2661 - categorical_accuracy: 0.9206 - val_loss: 0.6377 - val_categorical_accuracy: 0.8508\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2614 - categorical_accuracy: 0.9198 - val_loss: 0.6320 - val_categorical_accuracy: 0.8517\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2638 - categorical_accuracy: 0.9156 - val_loss: 0.6334 - val_categorical_accuracy: 0.8492\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2539 - categorical_accuracy: 0.9223 - val_loss: 0.6431 - val_categorical_accuracy: 0.8525\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2294 - categorical_accuracy: 0.9319 - val_loss: 0.6422 - val_categorical_accuracy: 0.8554\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2293 - categorical_accuracy: 0.9304 - val_loss: 0.6280 - val_categorical_accuracy: 0.8600\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2335 - categorical_accuracy: 0.9300 - val_loss: 0.6642 - val_categorical_accuracy: 0.8513\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2344 - categorical_accuracy: 0.9296 - val_loss: 0.6278 - val_categorical_accuracy: 0.8546\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2254 - categorical_accuracy: 0.9306 - val_loss: 0.6727 - val_categorical_accuracy: 0.8558\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2264 - categorical_accuracy: 0.9327 - val_loss: 0.6973 - val_categorical_accuracy: 0.8579\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2241 - categorical_accuracy: 0.9285 - val_loss: 0.6685 - val_categorical_accuracy: 0.8496\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2259 - categorical_accuracy: 0.9331 - val_loss: 0.6808 - val_categorical_accuracy: 0.8537\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2069 - categorical_accuracy: 0.9356 - val_loss: 0.6509 - val_categorical_accuracy: 0.8533\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2059 - categorical_accuracy: 0.9367 - val_loss: 0.6784 - val_categorical_accuracy: 0.8504\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.1971 - categorical_accuracy: 0.9410 - val_loss: 0.6678 - val_categorical_accuracy: 0.8571\n",
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2114 - categorical_accuracy: 0.9367 - val_loss: 0.7388 - val_categorical_accuracy: 0.8404\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2055 - categorical_accuracy: 0.9333 - val_loss: 0.7373 - val_categorical_accuracy: 0.8412\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.1999 - categorical_accuracy: 0.9381 - val_loss: 0.6801 - val_categorical_accuracy: 0.8488\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.1962 - categorical_accuracy: 0.9423 - val_loss: 0.6648 - val_categorical_accuracy: 0.8596\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.1890 - categorical_accuracy: 0.9425 - val_loss: 0.6644 - val_categorical_accuracy: 0.8521\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.1862 - categorical_accuracy: 0.9371 - val_loss: 0.6401 - val_categorical_accuracy: 0.8612\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.1926 - categorical_accuracy: 0.9408 - val_loss: 0.6390 - val_categorical_accuracy: 0.8608\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.1862 - categorical_accuracy: 0.9465 - val_loss: 0.6764 - val_categorical_accuracy: 0.8554\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.1782 - categorical_accuracy: 0.9446 - val_loss: 0.6292 - val_categorical_accuracy: 0.8638\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.1701 - categorical_accuracy: 0.9437 - val_loss: 0.6162 - val_categorical_accuracy: 0.8604\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.1703 - categorical_accuracy: 0.9456 - val_loss: 0.6667 - val_categorical_accuracy: 0.8621\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.1811 - categorical_accuracy: 0.9446 - val_loss: 0.6930 - val_categorical_accuracy: 0.8508\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.1727 - categorical_accuracy: 0.9458 - val_loss: 0.7124 - val_categorical_accuracy: 0.8521\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.1628 - categorical_accuracy: 0.9500 - val_loss: 0.6432 - val_categorical_accuracy: 0.8612\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.1722 - categorical_accuracy: 0.9454 - val_loss: 0.6846 - val_categorical_accuracy: 0.8554\n",
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.1705 - categorical_accuracy: 0.9458 - val_loss: 0.7090 - val_categorical_accuracy: 0.8546\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.1605 - categorical_accuracy: 0.9456 - val_loss: 0.6528 - val_categorical_accuracy: 0.8587\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.1606 - categorical_accuracy: 0.9521 - val_loss: 0.6952 - val_categorical_accuracy: 0.8458\n",
      "2400/2400 [==============================] - 1s 486us/step\n",
      "categorical_accuracy: 84.58%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 3s 556us/step - loss: 2.2773 - categorical_accuracy: 0.1535 - val_loss: 2.2124 - val_categorical_accuracy: 0.1913\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 2.1713 - categorical_accuracy: 0.1954 - val_loss: 2.0725 - val_categorical_accuracy: 0.2333\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 2.0411 - categorical_accuracy: 0.2523 - val_loss: 1.9119 - val_categorical_accuracy: 0.3417\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 1.8611 - categorical_accuracy: 0.3327 - val_loss: 1.7004 - val_categorical_accuracy: 0.3908\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 1.6696 - categorical_accuracy: 0.3994 - val_loss: 1.5423 - val_categorical_accuracy: 0.4396\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 1.5360 - categorical_accuracy: 0.4379 - val_loss: 1.4935 - val_categorical_accuracy: 0.4700\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 1.4193 - categorical_accuracy: 0.4912 - val_loss: 1.3255 - val_categorical_accuracy: 0.5579\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 1.2459 - categorical_accuracy: 0.5721 - val_loss: 1.1869 - val_categorical_accuracy: 0.6162\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 1.1155 - categorical_accuracy: 0.6267 - val_loss: 1.0565 - val_categorical_accuracy: 0.6537\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 1.0723 - categorical_accuracy: 0.6394 - val_loss: 1.0176 - val_categorical_accuracy: 0.6579\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.9279 - categorical_accuracy: 0.6894 - val_loss: 0.9292 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.8755 - categorical_accuracy: 0.7069 - val_loss: 0.8743 - val_categorical_accuracy: 0.7025\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.8245 - categorical_accuracy: 0.7267 - val_loss: 0.8635 - val_categorical_accuracy: 0.7121\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.7911 - categorical_accuracy: 0.7265 - val_loss: 0.8175 - val_categorical_accuracy: 0.7362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.7637 - categorical_accuracy: 0.7485 - val_loss: 0.7960 - val_categorical_accuracy: 0.7458\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.6977 - categorical_accuracy: 0.7702 - val_loss: 0.7782 - val_categorical_accuracy: 0.7504\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.6703 - categorical_accuracy: 0.7792 - val_loss: 0.7587 - val_categorical_accuracy: 0.7633\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6486 - categorical_accuracy: 0.7948 - val_loss: 0.7537 - val_categorical_accuracy: 0.7658\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6199 - categorical_accuracy: 0.7944 - val_loss: 0.7197 - val_categorical_accuracy: 0.7788\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6054 - categorical_accuracy: 0.8006 - val_loss: 0.7381 - val_categorical_accuracy: 0.7787\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.5686 - categorical_accuracy: 0.8183 - val_loss: 0.7469 - val_categorical_accuracy: 0.7829\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.5418 - categorical_accuracy: 0.8308 - val_loss: 0.7163 - val_categorical_accuracy: 0.7883\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.5270 - categorical_accuracy: 0.8279 - val_loss: 0.7605 - val_categorical_accuracy: 0.7842\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.5285 - categorical_accuracy: 0.8287 - val_loss: 0.7512 - val_categorical_accuracy: 0.7846\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.5139 - categorical_accuracy: 0.8356 - val_loss: 0.6743 - val_categorical_accuracy: 0.8021\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.4929 - categorical_accuracy: 0.8460 - val_loss: 0.6593 - val_categorical_accuracy: 0.8142\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.4784 - categorical_accuracy: 0.8504 - val_loss: 0.6952 - val_categorical_accuracy: 0.7954\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4647 - categorical_accuracy: 0.8490 - val_loss: 0.6654 - val_categorical_accuracy: 0.8158\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4535 - categorical_accuracy: 0.8542 - val_loss: 0.7184 - val_categorical_accuracy: 0.7950\n",
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4497 - categorical_accuracy: 0.8577 - val_loss: 0.6556 - val_categorical_accuracy: 0.8171\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.4311 - categorical_accuracy: 0.8656 - val_loss: 0.6776 - val_categorical_accuracy: 0.8113\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4147 - categorical_accuracy: 0.8690 - val_loss: 0.6779 - val_categorical_accuracy: 0.8121\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4095 - categorical_accuracy: 0.8671 - val_loss: 0.6341 - val_categorical_accuracy: 0.8263\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.3973 - categorical_accuracy: 0.8785 - val_loss: 0.6655 - val_categorical_accuracy: 0.8129\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3843 - categorical_accuracy: 0.8810 - val_loss: 0.6679 - val_categorical_accuracy: 0.8229\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.3722 - categorical_accuracy: 0.8887 - val_loss: 0.6612 - val_categorical_accuracy: 0.8158\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.3584 - categorical_accuracy: 0.8940 - val_loss: 0.6640 - val_categorical_accuracy: 0.8237\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.3534 - categorical_accuracy: 0.8935 - val_loss: 0.6842 - val_categorical_accuracy: 0.8167\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.3471 - categorical_accuracy: 0.8923 - val_loss: 0.6227 - val_categorical_accuracy: 0.8292\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.3230 - categorical_accuracy: 0.9038 - val_loss: 0.6947 - val_categorical_accuracy: 0.8200\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.3454 - categorical_accuracy: 0.8954 - val_loss: 0.6827 - val_categorical_accuracy: 0.8200\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3381 - categorical_accuracy: 0.8971 - val_loss: 0.7005 - val_categorical_accuracy: 0.8162\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3194 - categorical_accuracy: 0.9006 - val_loss: 0.6735 - val_categorical_accuracy: 0.8175\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.3383 - categorical_accuracy: 0.8931 - val_loss: 0.6827 - val_categorical_accuracy: 0.8262\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3157 - categorical_accuracy: 0.9027 - val_loss: 0.7028 - val_categorical_accuracy: 0.8225\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3041 - categorical_accuracy: 0.9008 - val_loss: 0.6655 - val_categorical_accuracy: 0.8237\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2916 - categorical_accuracy: 0.9156 - val_loss: 0.6357 - val_categorical_accuracy: 0.8346\n",
      "Epoch 48/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2803 - categorical_accuracy: 0.9202 - val_loss: 0.6875 - val_categorical_accuracy: 0.8246\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2999 - categorical_accuracy: 0.9071 - val_loss: 0.6794 - val_categorical_accuracy: 0.8308\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2840 - categorical_accuracy: 0.9142 - val_loss: 0.6274 - val_categorical_accuracy: 0.8367\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2695 - categorical_accuracy: 0.9202 - val_loss: 0.6552 - val_categorical_accuracy: 0.8413\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2750 - categorical_accuracy: 0.9150 - val_loss: 0.6960 - val_categorical_accuracy: 0.8242\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2677 - categorical_accuracy: 0.9246 - val_loss: 0.6850 - val_categorical_accuracy: 0.8267\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2806 - categorical_accuracy: 0.9148 - val_loss: 0.6713 - val_categorical_accuracy: 0.8296\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2831 - categorical_accuracy: 0.9085 - val_loss: 0.6657 - val_categorical_accuracy: 0.8308\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2592 - categorical_accuracy: 0.9171 - val_loss: 0.6542 - val_categorical_accuracy: 0.8392\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2550 - categorical_accuracy: 0.9185 - val_loss: 0.6787 - val_categorical_accuracy: 0.8362\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2410 - categorical_accuracy: 0.9298 - val_loss: 0.7142 - val_categorical_accuracy: 0.8246\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2322 - categorical_accuracy: 0.9292 - val_loss: 0.7112 - val_categorical_accuracy: 0.8283\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2561 - categorical_accuracy: 0.9202 - val_loss: 0.6731 - val_categorical_accuracy: 0.8367\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2364 - categorical_accuracy: 0.9306 - val_loss: 0.6903 - val_categorical_accuracy: 0.8346\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2290 - categorical_accuracy: 0.9277 - val_loss: 0.6715 - val_categorical_accuracy: 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.2269 - categorical_accuracy: 0.9327 - val_loss: 0.6478 - val_categorical_accuracy: 0.8458\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2144 - categorical_accuracy: 0.9325 - val_loss: 0.6965 - val_categorical_accuracy: 0.8358\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2186 - categorical_accuracy: 0.9308 - val_loss: 0.6826 - val_categorical_accuracy: 0.8433\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2172 - categorical_accuracy: 0.9325 - val_loss: 0.6823 - val_categorical_accuracy: 0.8383\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2138 - categorical_accuracy: 0.9358 - val_loss: 0.7204 - val_categorical_accuracy: 0.8321\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2234 - categorical_accuracy: 0.9310 - val_loss: 0.6613 - val_categorical_accuracy: 0.8362\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2180 - categorical_accuracy: 0.9348 - val_loss: 0.6133 - val_categorical_accuracy: 0.8483\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2197 - categorical_accuracy: 0.9352 - val_loss: 0.6970 - val_categorical_accuracy: 0.8408\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2071 - categorical_accuracy: 0.9377 - val_loss: 0.6861 - val_categorical_accuracy: 0.8417\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2180 - categorical_accuracy: 0.9333 - val_loss: 0.6520 - val_categorical_accuracy: 0.8467\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2050 - categorical_accuracy: 0.9342 - val_loss: 0.6952 - val_categorical_accuracy: 0.8392\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.2313 - categorical_accuracy: 0.9302 - val_loss: 0.6511 - val_categorical_accuracy: 0.8446\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.2118 - categorical_accuracy: 0.9342 - val_loss: 0.6466 - val_categorical_accuracy: 0.8517\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.1976 - categorical_accuracy: 0.9400 - val_loss: 0.6893 - val_categorical_accuracy: 0.8429\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.1838 - categorical_accuracy: 0.9442 - val_loss: 0.6898 - val_categorical_accuracy: 0.8450\n",
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 252us/step - loss: 0.1984 - categorical_accuracy: 0.9392 - val_loss: 0.7628 - val_categorical_accuracy: 0.8317\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.1848 - categorical_accuracy: 0.9437 - val_loss: 0.7086 - val_categorical_accuracy: 0.8383\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.1861 - categorical_accuracy: 0.9452 - val_loss: 0.6736 - val_categorical_accuracy: 0.8429\n",
      "2400/2400 [==============================] - 1s 493us/step\n",
      "categorical_accuracy: 84.29%\n",
      "\n",
      "....................\n",
      "Cross validation fold [3]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 3s 586us/step - loss: 2.2646 - categorical_accuracy: 0.1525 - val_loss: 2.1678 - val_categorical_accuracy: 0.2017\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 252us/step - loss: 2.1290 - categorical_accuracy: 0.2058 - val_loss: 2.0237 - val_categorical_accuracy: 0.2833\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 253us/step - loss: 2.0110 - categorical_accuracy: 0.2690 - val_loss: 1.9004 - val_categorical_accuracy: 0.3371\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 253us/step - loss: 1.8377 - categorical_accuracy: 0.3448 - val_loss: 1.7093 - val_categorical_accuracy: 0.4017\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 1.6312 - categorical_accuracy: 0.4188 - val_loss: 1.4426 - val_categorical_accuracy: 0.5092\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 251us/step - loss: 1.4240 - categorical_accuracy: 0.5094 - val_loss: 1.3036 - val_categorical_accuracy: 0.5558\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 253us/step - loss: 1.2921 - categorical_accuracy: 0.5573 - val_loss: 1.2365 - val_categorical_accuracy: 0.5746\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 1.1986 - categorical_accuracy: 0.5804 - val_loss: 1.1147 - val_categorical_accuracy: 0.6242\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 1.1053 - categorical_accuracy: 0.6192 - val_loss: 1.0935 - val_categorical_accuracy: 0.6363\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 1.0608 - categorical_accuracy: 0.6435 - val_loss: 1.0465 - val_categorical_accuracy: 0.6467\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.9834 - categorical_accuracy: 0.6665 - val_loss: 0.9602 - val_categorical_accuracy: 0.6917\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.9139 - categorical_accuracy: 0.6906 - val_loss: 0.9071 - val_categorical_accuracy: 0.7075\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 294us/step - loss: 0.8430 - categorical_accuracy: 0.7269 - val_loss: 0.8770 - val_categorical_accuracy: 0.7221\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 280us/step - loss: 0.7929 - categorical_accuracy: 0.7329 - val_loss: 0.8391 - val_categorical_accuracy: 0.7317\n",
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.7695 - categorical_accuracy: 0.7481 - val_loss: 0.7927 - val_categorical_accuracy: 0.7458\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 273us/step - loss: 0.7121 - categorical_accuracy: 0.7623 - val_loss: 0.7844 - val_categorical_accuracy: 0.7546\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.6691 - categorical_accuracy: 0.7815 - val_loss: 0.7442 - val_categorical_accuracy: 0.7771\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.6450 - categorical_accuracy: 0.7910 - val_loss: 0.7227 - val_categorical_accuracy: 0.7875\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.6062 - categorical_accuracy: 0.8150 - val_loss: 0.7254 - val_categorical_accuracy: 0.7833\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.5872 - categorical_accuracy: 0.8135 - val_loss: 0.6947 - val_categorical_accuracy: 0.7917\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.5667 - categorical_accuracy: 0.8258 - val_loss: 0.7042 - val_categorical_accuracy: 0.7896\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.5460 - categorical_accuracy: 0.8217 - val_loss: 0.6807 - val_categorical_accuracy: 0.8000\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.5193 - categorical_accuracy: 0.8346 - val_loss: 0.6792 - val_categorical_accuracy: 0.8025\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.5201 - categorical_accuracy: 0.8367 - val_loss: 0.6549 - val_categorical_accuracy: 0.8125\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.4994 - categorical_accuracy: 0.8467 - val_loss: 0.6705 - val_categorical_accuracy: 0.8033\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4730 - categorical_accuracy: 0.8504 - val_loss: 0.6335 - val_categorical_accuracy: 0.8200\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4671 - categorical_accuracy: 0.8594 - val_loss: 0.6960 - val_categorical_accuracy: 0.8050\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.4593 - categorical_accuracy: 0.8638 - val_loss: 0.6600 - val_categorical_accuracy: 0.8087\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.4546 - categorical_accuracy: 0.8573 - val_loss: 0.6348 - val_categorical_accuracy: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4419 - categorical_accuracy: 0.8675 - val_loss: 0.6854 - val_categorical_accuracy: 0.8042\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.4204 - categorical_accuracy: 0.8621 - val_loss: 0.6759 - val_categorical_accuracy: 0.8112\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4111 - categorical_accuracy: 0.8746 - val_loss: 0.7005 - val_categorical_accuracy: 0.8008\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3968 - categorical_accuracy: 0.8806 - val_loss: 0.6562 - val_categorical_accuracy: 0.8188\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3965 - categorical_accuracy: 0.8794 - val_loss: 0.6372 - val_categorical_accuracy: 0.8163\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.4011 - categorical_accuracy: 0.8744 - val_loss: 0.6116 - val_categorical_accuracy: 0.8287\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.3888 - categorical_accuracy: 0.8846 - val_loss: 0.6684 - val_categorical_accuracy: 0.8233\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.3873 - categorical_accuracy: 0.8825 - val_loss: 0.6282 - val_categorical_accuracy: 0.8238\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.3641 - categorical_accuracy: 0.8890 - val_loss: 0.6264 - val_categorical_accuracy: 0.8333\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3714 - categorical_accuracy: 0.8873 - val_loss: 0.6733 - val_categorical_accuracy: 0.8046\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3588 - categorical_accuracy: 0.8894 - val_loss: 0.6223 - val_categorical_accuracy: 0.8317\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.3616 - categorical_accuracy: 0.8871 - val_loss: 0.6423 - val_categorical_accuracy: 0.8225\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.3549 - categorical_accuracy: 0.8881 - val_loss: 0.6430 - val_categorical_accuracy: 0.8283\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.3570 - categorical_accuracy: 0.8885 - val_loss: 0.6485 - val_categorical_accuracy: 0.8221\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3313 - categorical_accuracy: 0.8977 - val_loss: 0.6325 - val_categorical_accuracy: 0.8242\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.3247 - categorical_accuracy: 0.8998 - val_loss: 0.6022 - val_categorical_accuracy: 0.8338\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.3303 - categorical_accuracy: 0.8958 - val_loss: 0.6524 - val_categorical_accuracy: 0.8179\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3189 - categorical_accuracy: 0.9023 - val_loss: 0.6061 - val_categorical_accuracy: 0.8388\n",
      "Epoch 48/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.3100 - categorical_accuracy: 0.9033 - val_loss: 0.6343 - val_categorical_accuracy: 0.8337\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.3079 - categorical_accuracy: 0.9025 - val_loss: 0.5990 - val_categorical_accuracy: 0.8308\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2891 - categorical_accuracy: 0.9106 - val_loss: 0.5981 - val_categorical_accuracy: 0.8317\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.2938 - categorical_accuracy: 0.9102 - val_loss: 0.6110 - val_categorical_accuracy: 0.8287\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2956 - categorical_accuracy: 0.9060 - val_loss: 0.5881 - val_categorical_accuracy: 0.8375\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2765 - categorical_accuracy: 0.9148 - val_loss: 0.6242 - val_categorical_accuracy: 0.8250\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2883 - categorical_accuracy: 0.9160 - val_loss: 0.6541 - val_categorical_accuracy: 0.8267\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2745 - categorical_accuracy: 0.9135 - val_loss: 0.6068 - val_categorical_accuracy: 0.8367\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2820 - categorical_accuracy: 0.9138 - val_loss: 0.6049 - val_categorical_accuracy: 0.8346\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2609 - categorical_accuracy: 0.9204 - val_loss: 0.6244 - val_categorical_accuracy: 0.8375\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2842 - categorical_accuracy: 0.9135 - val_loss: 0.6137 - val_categorical_accuracy: 0.8325\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2643 - categorical_accuracy: 0.9217 - val_loss: 0.6058 - val_categorical_accuracy: 0.8367\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2526 - categorical_accuracy: 0.9223 - val_loss: 0.5997 - val_categorical_accuracy: 0.8429\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2474 - categorical_accuracy: 0.9225 - val_loss: 0.6443 - val_categorical_accuracy: 0.8358\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2394 - categorical_accuracy: 0.9231 - val_loss: 0.6327 - val_categorical_accuracy: 0.8354\n",
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2519 - categorical_accuracy: 0.9258 - val_loss: 0.6027 - val_categorical_accuracy: 0.8383\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2410 - categorical_accuracy: 0.9294 - val_loss: 0.5929 - val_categorical_accuracy: 0.8350\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2413 - categorical_accuracy: 0.9242 - val_loss: 0.6482 - val_categorical_accuracy: 0.8404\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2513 - categorical_accuracy: 0.9244 - val_loss: 0.6246 - val_categorical_accuracy: 0.8321\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2520 - categorical_accuracy: 0.9235 - val_loss: 0.5919 - val_categorical_accuracy: 0.8421\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2393 - categorical_accuracy: 0.9252 - val_loss: 0.6110 - val_categorical_accuracy: 0.8500\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2404 - categorical_accuracy: 0.9302 - val_loss: 0.5826 - val_categorical_accuracy: 0.8483\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2282 - categorical_accuracy: 0.9327 - val_loss: 0.5800 - val_categorical_accuracy: 0.8521\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2178 - categorical_accuracy: 0.9360 - val_loss: 0.6175 - val_categorical_accuracy: 0.8379\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2267 - categorical_accuracy: 0.9283 - val_loss: 0.5860 - val_categorical_accuracy: 0.8454\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2149 - categorical_accuracy: 0.9333 - val_loss: 0.6101 - val_categorical_accuracy: 0.8404\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2063 - categorical_accuracy: 0.9379 - val_loss: 0.5992 - val_categorical_accuracy: 0.8438\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2131 - categorical_accuracy: 0.9354 - val_loss: 0.6115 - val_categorical_accuracy: 0.8504\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2204 - categorical_accuracy: 0.9333 - val_loss: 0.5997 - val_categorical_accuracy: 0.8429\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2022 - categorical_accuracy: 0.9400 - val_loss: 0.6183 - val_categorical_accuracy: 0.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.2068 - categorical_accuracy: 0.9394 - val_loss: 0.6188 - val_categorical_accuracy: 0.8371\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.1921 - categorical_accuracy: 0.9415 - val_loss: 0.6359 - val_categorical_accuracy: 0.8362\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.1998 - categorical_accuracy: 0.9419 - val_loss: 0.6337 - val_categorical_accuracy: 0.8421\n",
      "2400/2400 [==============================] - 1s 489us/step\n",
      "categorical_accuracy: 84.21%\n",
      "84.36% (+/- 0.16%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84.583333333333329, 84.291666666666671, 84.208333333333329]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 80\n",
    "PARAM_BATCH_SIZE = 300\n",
    "\n",
    "from models.regularized_64_gru import Regularized64GRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = Regularized64GRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y Axis Only:\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only X axis values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 50, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_orig[:, :, 1].reshape(X_train_orig.shape[0], X_train_orig.shape[1], 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## **Regularized Deep GRU**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 912us/step - loss: 2.2028 - categorical_accuracy: 0.1706 - val_loss: 2.0603 - val_categorical_accuracy: 0.1846\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 660us/step - loss: 1.9810 - categorical_accuracy: 0.2435 - val_loss: 1.8168 - val_categorical_accuracy: 0.3667\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 660us/step - loss: 1.7198 - categorical_accuracy: 0.3373 - val_loss: 1.6276 - val_categorical_accuracy: 0.4113\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 665us/step - loss: 1.5734 - categorical_accuracy: 0.4065 - val_loss: 1.4838 - val_categorical_accuracy: 0.4850\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 1.3752 - categorical_accuracy: 0.4837 - val_loss: 1.4284 - val_categorical_accuracy: 0.4950\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 1.1679 - categorical_accuracy: 0.5640 - val_loss: 1.3196 - val_categorical_accuracy: 0.5442\n",
      "Epoch 7/40\n",
      "4800/4800 [==============================] - 3s 658us/step - loss: 1.0753 - categorical_accuracy: 0.5990 - val_loss: 1.1585 - val_categorical_accuracy: 0.6075\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 658us/step - loss: 0.9304 - categorical_accuracy: 0.6623 - val_loss: 1.0692 - val_categorical_accuracy: 0.6517\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 0.8507 - categorical_accuracy: 0.6837 - val_loss: 1.0260 - val_categorical_accuracy: 0.6658\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 722us/step - loss: 0.7363 - categorical_accuracy: 0.7313 - val_loss: 0.9149 - val_categorical_accuracy: 0.7125\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 714us/step - loss: 0.7165 - categorical_accuracy: 0.7429 - val_loss: 0.8840 - val_categorical_accuracy: 0.7296\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 675us/step - loss: 0.6106 - categorical_accuracy: 0.7863 - val_loss: 0.8951 - val_categorical_accuracy: 0.7175\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 676us/step - loss: 0.5525 - categorical_accuracy: 0.8033 - val_loss: 0.9163 - val_categorical_accuracy: 0.7183\n",
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 684us/step - loss: 0.5548 - categorical_accuracy: 0.8056 - val_loss: 0.8258 - val_categorical_accuracy: 0.7517\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 4s 732us/step - loss: 0.4682 - categorical_accuracy: 0.8365 - val_loss: 0.7364 - val_categorical_accuracy: 0.7846\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 720us/step - loss: 0.4401 - categorical_accuracy: 0.8450 - val_loss: 0.7456 - val_categorical_accuracy: 0.7900\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.4098 - categorical_accuracy: 0.8592 - val_loss: 0.7294 - val_categorical_accuracy: 0.8021\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 664us/step - loss: 0.3686 - categorical_accuracy: 0.8721 - val_loss: 0.7321 - val_categorical_accuracy: 0.8017\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 663us/step - loss: 0.3590 - categorical_accuracy: 0.8779 - val_loss: 0.8036 - val_categorical_accuracy: 0.7846\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.3387 - categorical_accuracy: 0.8852 - val_loss: 0.7368 - val_categorical_accuracy: 0.8079\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 663us/step - loss: 0.3114 - categorical_accuracy: 0.8996 - val_loss: 0.6917 - val_categorical_accuracy: 0.8217\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.3022 - categorical_accuracy: 0.8975 - val_loss: 0.7484 - val_categorical_accuracy: 0.8025\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 655us/step - loss: 0.2963 - categorical_accuracy: 0.8994 - val_loss: 0.7031 - val_categorical_accuracy: 0.8283\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 674us/step - loss: 0.2669 - categorical_accuracy: 0.9085 - val_loss: 0.7156 - val_categorical_accuracy: 0.8246\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 660us/step - loss: 0.2498 - categorical_accuracy: 0.9192 - val_loss: 0.7076 - val_categorical_accuracy: 0.8325\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 677us/step - loss: 0.2264 - categorical_accuracy: 0.9294 - val_loss: 0.7284 - val_categorical_accuracy: 0.8196\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.2265 - categorical_accuracy: 0.9260 - val_loss: 0.7009 - val_categorical_accuracy: 0.8217\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 683us/step - loss: 0.2221 - categorical_accuracy: 0.9302 - val_loss: 0.7338 - val_categorical_accuracy: 0.8267\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 672us/step - loss: 0.1968 - categorical_accuracy: 0.9396 - val_loss: 0.6791 - val_categorical_accuracy: 0.8475\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 653us/step - loss: 0.1896 - categorical_accuracy: 0.9367 - val_loss: 0.7458 - val_categorical_accuracy: 0.8308\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 665us/step - loss: 0.1925 - categorical_accuracy: 0.9398 - val_loss: 0.6639 - val_categorical_accuracy: 0.8488\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.1673 - categorical_accuracy: 0.9440 - val_loss: 0.6673 - val_categorical_accuracy: 0.8492\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 695us/step - loss: 0.1705 - categorical_accuracy: 0.9456 - val_loss: 0.6888 - val_categorical_accuracy: 0.8413\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 704us/step - loss: 0.1474 - categorical_accuracy: 0.9529 - val_loss: 0.7043 - val_categorical_accuracy: 0.8442\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.1491 - categorical_accuracy: 0.9546 - val_loss: 0.7144 - val_categorical_accuracy: 0.8425\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.1400 - categorical_accuracy: 0.9552 - val_loss: 0.7111 - val_categorical_accuracy: 0.8438\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 698us/step - loss: 0.1521 - categorical_accuracy: 0.9512 - val_loss: 0.7347 - val_categorical_accuracy: 0.8458\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 704us/step - loss: 0.1224 - categorical_accuracy: 0.9596 - val_loss: 0.6717 - val_categorical_accuracy: 0.8613\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 715us/step - loss: 0.1170 - categorical_accuracy: 0.9640 - val_loss: 0.7333 - val_categorical_accuracy: 0.8442\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 729us/step - loss: 0.1043 - categorical_accuracy: 0.9679 - val_loss: 0.7013 - val_categorical_accuracy: 0.8571\n",
      "2400/2400 [==============================] - 1s 488us/step\n",
      "categorical_accuracy: 85.71%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 883us/step - loss: 2.2148 - categorical_accuracy: 0.1569 - val_loss: 2.1055 - val_categorical_accuracy: 0.2171\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 710us/step - loss: 2.0069 - categorical_accuracy: 0.2321 - val_loss: 1.7055 - val_categorical_accuracy: 0.3683\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 707us/step - loss: 1.7697 - categorical_accuracy: 0.3375 - val_loss: 1.4799 - val_categorical_accuracy: 0.4817\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 708us/step - loss: 1.6602 - categorical_accuracy: 0.3904 - val_loss: 1.3538 - val_categorical_accuracy: 0.5171\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 1.3934 - categorical_accuracy: 0.4927 - val_loss: 1.3627 - val_categorical_accuracy: 0.4904\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 707us/step - loss: 1.2822 - categorical_accuracy: 0.5400 - val_loss: 0.9487 - val_categorical_accuracy: 0.6675\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 3s 680us/step - loss: 1.1614 - categorical_accuracy: 0.5892 - val_loss: 1.0361 - val_categorical_accuracy: 0.6133\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 658us/step - loss: 1.0204 - categorical_accuracy: 0.6406 - val_loss: 0.8220 - val_categorical_accuracy: 0.6937\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 1.0076 - categorical_accuracy: 0.6385 - val_loss: 0.7537 - val_categorical_accuracy: 0.7300\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 706us/step - loss: 0.8474 - categorical_accuracy: 0.7119 - val_loss: 0.6771 - val_categorical_accuracy: 0.7713\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 706us/step - loss: 0.7771 - categorical_accuracy: 0.7344 - val_loss: 0.6307 - val_categorical_accuracy: 0.7779\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 0.6961 - categorical_accuracy: 0.7640 - val_loss: 0.5559 - val_categorical_accuracy: 0.8113\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 715us/step - loss: 0.6680 - categorical_accuracy: 0.7679 - val_loss: 0.5342 - val_categorical_accuracy: 0.8100\n",
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 715us/step - loss: 0.5762 - categorical_accuracy: 0.8081 - val_loss: 0.4707 - val_categorical_accuracy: 0.8362\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 726us/step - loss: 0.5059 - categorical_accuracy: 0.8373 - val_loss: 0.4558 - val_categorical_accuracy: 0.8375\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 719us/step - loss: 0.5147 - categorical_accuracy: 0.8323 - val_loss: 0.4837 - val_categorical_accuracy: 0.8321\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 705us/step - loss: 0.4691 - categorical_accuracy: 0.8475 - val_loss: 0.4200 - val_categorical_accuracy: 0.8533\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 725us/step - loss: 0.4354 - categorical_accuracy: 0.8594 - val_loss: 0.4479 - val_categorical_accuracy: 0.8504\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 728us/step - loss: 0.4147 - categorical_accuracy: 0.8656 - val_loss: 0.3710 - val_categorical_accuracy: 0.8679\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 4s 733us/step - loss: 0.3672 - categorical_accuracy: 0.8852 - val_loss: 0.3861 - val_categorical_accuracy: 0.8687\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 697us/step - loss: 0.3432 - categorical_accuracy: 0.8890 - val_loss: 0.3873 - val_categorical_accuracy: 0.8646\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 719us/step - loss: 0.3373 - categorical_accuracy: 0.8942 - val_loss: 0.4088 - val_categorical_accuracy: 0.8629\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 716us/step - loss: 0.3131 - categorical_accuracy: 0.9017 - val_loss: 0.3766 - val_categorical_accuracy: 0.8704\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 718us/step - loss: 0.2915 - categorical_accuracy: 0.9048 - val_loss: 0.3353 - val_categorical_accuracy: 0.8883\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 708us/step - loss: 0.2810 - categorical_accuracy: 0.9083 - val_loss: 0.3980 - val_categorical_accuracy: 0.8683\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 709us/step - loss: 0.2865 - categorical_accuracy: 0.9073 - val_loss: 0.3715 - val_categorical_accuracy: 0.8800\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 688us/step - loss: 0.2504 - categorical_accuracy: 0.9204 - val_loss: 0.3716 - val_categorical_accuracy: 0.8821\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 0.2287 - categorical_accuracy: 0.9300 - val_loss: 0.3384 - val_categorical_accuracy: 0.8938\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 0.2328 - categorical_accuracy: 0.9260 - val_loss: 0.3522 - val_categorical_accuracy: 0.8850\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 713us/step - loss: 0.2079 - categorical_accuracy: 0.9346 - val_loss: 0.3231 - val_categorical_accuracy: 0.8983\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 717us/step - loss: 0.2002 - categorical_accuracy: 0.9369 - val_loss: 0.3234 - val_categorical_accuracy: 0.9071\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 697us/step - loss: 0.1793 - categorical_accuracy: 0.9433 - val_loss: 0.3206 - val_categorical_accuracy: 0.9063\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.1815 - categorical_accuracy: 0.9431 - val_loss: 0.3400 - val_categorical_accuracy: 0.9008\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 709us/step - loss: 0.1602 - categorical_accuracy: 0.9552 - val_loss: 0.3419 - val_categorical_accuracy: 0.8983\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 716us/step - loss: 0.1613 - categorical_accuracy: 0.9475 - val_loss: 0.2941 - val_categorical_accuracy: 0.9113\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 701us/step - loss: 0.1553 - categorical_accuracy: 0.9525 - val_loss: 0.3233 - val_categorical_accuracy: 0.9046\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 671us/step - loss: 0.1347 - categorical_accuracy: 0.9571 - val_loss: 0.3216 - val_categorical_accuracy: 0.9104\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 690us/step - loss: 0.1400 - categorical_accuracy: 0.9560 - val_loss: 0.3776 - val_categorical_accuracy: 0.8954\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 694us/step - loss: 0.1378 - categorical_accuracy: 0.9573 - val_loss: 0.3629 - val_categorical_accuracy: 0.9004\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 0.1284 - categorical_accuracy: 0.9571 - val_loss: 0.3862 - val_categorical_accuracy: 0.8921\n",
      "2400/2400 [==============================] - 1s 517us/step\n",
      "categorical_accuracy: 89.21%\n",
      "\n",
      "....................\n",
      "Cross validation fold [3]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 922us/step - loss: 2.1989 - categorical_accuracy: 0.1681 - val_loss: 2.1117 - val_categorical_accuracy: 0.1617\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 718us/step - loss: 1.9659 - categorical_accuracy: 0.2602 - val_loss: 1.7900 - val_categorical_accuracy: 0.3317\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 723us/step - loss: 1.7845 - categorical_accuracy: 0.3162 - val_loss: 1.6134 - val_categorical_accuracy: 0.3883\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 712us/step - loss: 1.5340 - categorical_accuracy: 0.4294 - val_loss: 2.1396 - val_categorical_accuracy: 0.2196\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 718us/step - loss: 1.3870 - categorical_accuracy: 0.4948 - val_loss: 1.3050 - val_categorical_accuracy: 0.5513\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 709us/step - loss: 1.2528 - categorical_accuracy: 0.5319 - val_loss: 1.1257 - val_categorical_accuracy: 0.6142\n",
      "Epoch 7/40\n",
      "4800/4800 [==============================] - 3s 712us/step - loss: 1.0550 - categorical_accuracy: 0.6183 - val_loss: 1.0688 - val_categorical_accuracy: 0.6554\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 710us/step - loss: 1.0578 - categorical_accuracy: 0.6115 - val_loss: 1.0054 - val_categorical_accuracy: 0.6625\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 0.9343 - categorical_accuracy: 0.6600 - val_loss: 0.9078 - val_categorical_accuracy: 0.7054\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 706us/step - loss: 0.7978 - categorical_accuracy: 0.7188 - val_loss: 0.8491 - val_categorical_accuracy: 0.7204\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 708us/step - loss: 0.7569 - categorical_accuracy: 0.7331 - val_loss: 0.8227 - val_categorical_accuracy: 0.7271\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 713us/step - loss: 0.7190 - categorical_accuracy: 0.7435 - val_loss: 0.7897 - val_categorical_accuracy: 0.7437\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 675us/step - loss: 0.6258 - categorical_accuracy: 0.7756 - val_loss: 0.8587 - val_categorical_accuracy: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.5759 - categorical_accuracy: 0.8015 - val_loss: 0.7315 - val_categorical_accuracy: 0.7608\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 710us/step - loss: 0.5871 - categorical_accuracy: 0.7898 - val_loss: 0.7173 - val_categorical_accuracy: 0.7696\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 708us/step - loss: 0.4961 - categorical_accuracy: 0.8281 - val_loss: 0.6586 - val_categorical_accuracy: 0.7888\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 720us/step - loss: 0.4498 - categorical_accuracy: 0.8473 - val_loss: 0.6525 - val_categorical_accuracy: 0.7892\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 4s 731us/step - loss: 0.4306 - categorical_accuracy: 0.8485 - val_loss: 0.6442 - val_categorical_accuracy: 0.7967\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 727us/step - loss: 0.3932 - categorical_accuracy: 0.8667 - val_loss: 0.6061 - val_categorical_accuracy: 0.8121\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 695us/step - loss: 0.3687 - categorical_accuracy: 0.8754 - val_loss: 0.6368 - val_categorical_accuracy: 0.8008\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 709us/step - loss: 0.3634 - categorical_accuracy: 0.8802 - val_loss: 0.5928 - val_categorical_accuracy: 0.8167\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 0.3397 - categorical_accuracy: 0.8817 - val_loss: 0.5769 - val_categorical_accuracy: 0.8250\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 722us/step - loss: 0.3262 - categorical_accuracy: 0.8927 - val_loss: 0.5877 - val_categorical_accuracy: 0.8225\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 717us/step - loss: 0.2985 - categorical_accuracy: 0.9002 - val_loss: 0.5642 - val_categorical_accuracy: 0.8358\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 708us/step - loss: 0.2922 - categorical_accuracy: 0.9008 - val_loss: 0.6094 - val_categorical_accuracy: 0.8150\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 705us/step - loss: 0.2718 - categorical_accuracy: 0.9090 - val_loss: 0.5861 - val_categorical_accuracy: 0.8296\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 721us/step - loss: 0.2445 - categorical_accuracy: 0.9206 - val_loss: 0.5357 - val_categorical_accuracy: 0.8475\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 716us/step - loss: 0.2449 - categorical_accuracy: 0.9173 - val_loss: 0.5701 - val_categorical_accuracy: 0.8429\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 696us/step - loss: 0.2367 - categorical_accuracy: 0.9196 - val_loss: 0.5394 - val_categorical_accuracy: 0.8563\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.2075 - categorical_accuracy: 0.9331 - val_loss: 0.5469 - val_categorical_accuracy: 0.8550\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.2028 - categorical_accuracy: 0.9304 - val_loss: 0.5224 - val_categorical_accuracy: 0.8671\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.1951 - categorical_accuracy: 0.9406 - val_loss: 0.5863 - val_categorical_accuracy: 0.8571\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 686us/step - loss: 0.1929 - categorical_accuracy: 0.9356 - val_loss: 0.5369 - val_categorical_accuracy: 0.8696\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 697us/step - loss: 0.1810 - categorical_accuracy: 0.9377 - val_loss: 0.5950 - val_categorical_accuracy: 0.8387\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 671us/step - loss: 0.1673 - categorical_accuracy: 0.9465 - val_loss: 0.5451 - val_categorical_accuracy: 0.8637\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 690us/step - loss: 0.1566 - categorical_accuracy: 0.9492 - val_loss: 0.5199 - val_categorical_accuracy: 0.8679\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 684us/step - loss: 0.1475 - categorical_accuracy: 0.9515 - val_loss: 0.5384 - val_categorical_accuracy: 0.8679\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 684us/step - loss: 0.1614 - categorical_accuracy: 0.9456 - val_loss: 0.6222 - val_categorical_accuracy: 0.8517\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 676us/step - loss: 0.1567 - categorical_accuracy: 0.9475 - val_loss: 0.5183 - val_categorical_accuracy: 0.8708\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 694us/step - loss: 0.1468 - categorical_accuracy: 0.9535 - val_loss: 0.5268 - val_categorical_accuracy: 0.8708\n",
      "2400/2400 [==============================] - 1s 502us/step\n",
      "categorical_accuracy: 87.08%\n",
      "87.33% (+/- 1.44%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[85.708333333333329, 89.208333333333329, 87.083333333333329]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 40\n",
    "PARAM_BATCH_SIZE = 300\n",
    "\n",
    "from models.regularized_deep_gru import RegularizedDeepGRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = RegularizedDeepGRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## **Regularized 64 GRU**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 2s 454us/step - loss: 2.2539 - categorical_accuracy: 0.1415 - val_loss: 2.1930 - val_categorical_accuracy: 0.1650\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 2.1493 - categorical_accuracy: 0.1746 - val_loss: 2.1646 - val_categorical_accuracy: 0.1908\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 1.9502 - categorical_accuracy: 0.2437 - val_loss: 1.9016 - val_categorical_accuracy: 0.3521\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 1.7433 - categorical_accuracy: 0.3321 - val_loss: 1.6424 - val_categorical_accuracy: 0.4142\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.5845 - categorical_accuracy: 0.4027 - val_loss: 1.5029 - val_categorical_accuracy: 0.4733\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.4272 - categorical_accuracy: 0.4704 - val_loss: 1.3820 - val_categorical_accuracy: 0.5317\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 1.2938 - categorical_accuracy: 0.5183 - val_loss: 1.3174 - val_categorical_accuracy: 0.5333\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.1914 - categorical_accuracy: 0.5602 - val_loss: 1.2228 - val_categorical_accuracy: 0.5975\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 273us/step - loss: 1.0951 - categorical_accuracy: 0.5979 - val_loss: 1.1682 - val_categorical_accuracy: 0.6079\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 273us/step - loss: 1.0278 - categorical_accuracy: 0.6127 - val_loss: 1.1099 - val_categorical_accuracy: 0.6371\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.9492 - categorical_accuracy: 0.6473 - val_loss: 1.1086 - val_categorical_accuracy: 0.6429\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.9348 - categorical_accuracy: 0.6529 - val_loss: 1.0560 - val_categorical_accuracy: 0.6650\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.8632 - categorical_accuracy: 0.6763 - val_loss: 1.0484 - val_categorical_accuracy: 0.6717\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.8266 - categorical_accuracy: 0.6973 - val_loss: 1.0192 - val_categorical_accuracy: 0.6583\n",
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.7890 - categorical_accuracy: 0.7135 - val_loss: 1.0443 - val_categorical_accuracy: 0.6758\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.7576 - categorical_accuracy: 0.7229 - val_loss: 0.9775 - val_categorical_accuracy: 0.6854\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.7360 - categorical_accuracy: 0.7408 - val_loss: 1.0117 - val_categorical_accuracy: 0.6733\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.7129 - categorical_accuracy: 0.7410 - val_loss: 0.9331 - val_categorical_accuracy: 0.7125\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.6762 - categorical_accuracy: 0.7625 - val_loss: 0.9360 - val_categorical_accuracy: 0.6858\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 282us/step - loss: 0.6499 - categorical_accuracy: 0.7733 - val_loss: 0.8933 - val_categorical_accuracy: 0.7288\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.6520 - categorical_accuracy: 0.7683 - val_loss: 0.9065 - val_categorical_accuracy: 0.7258\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.6117 - categorical_accuracy: 0.7829 - val_loss: 0.8691 - val_categorical_accuracy: 0.7333\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.5974 - categorical_accuracy: 0.7902 - val_loss: 0.8246 - val_categorical_accuracy: 0.7521\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.5457 - categorical_accuracy: 0.8081 - val_loss: 0.8102 - val_categorical_accuracy: 0.7587\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.5576 - categorical_accuracy: 0.8085 - val_loss: 0.8308 - val_categorical_accuracy: 0.7550\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.5351 - categorical_accuracy: 0.8154 - val_loss: 0.7953 - val_categorical_accuracy: 0.7604\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.5240 - categorical_accuracy: 0.8198 - val_loss: 0.7813 - val_categorical_accuracy: 0.7762\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.5082 - categorical_accuracy: 0.8260 - val_loss: 0.7949 - val_categorical_accuracy: 0.7750\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.4920 - categorical_accuracy: 0.8327 - val_loss: 0.7495 - val_categorical_accuracy: 0.7933\n",
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.4857 - categorical_accuracy: 0.8369 - val_loss: 0.8080 - val_categorical_accuracy: 0.7679\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.4704 - categorical_accuracy: 0.8383 - val_loss: 0.7655 - val_categorical_accuracy: 0.7812\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.4385 - categorical_accuracy: 0.8538 - val_loss: 0.7598 - val_categorical_accuracy: 0.7900\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4419 - categorical_accuracy: 0.8492 - val_loss: 0.8378 - val_categorical_accuracy: 0.7608\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.4344 - categorical_accuracy: 0.8598 - val_loss: 0.7771 - val_categorical_accuracy: 0.7896\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.4218 - categorical_accuracy: 0.8550 - val_loss: 0.7710 - val_categorical_accuracy: 0.7979\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.4084 - categorical_accuracy: 0.8610 - val_loss: 0.7670 - val_categorical_accuracy: 0.7996\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.4116 - categorical_accuracy: 0.8635 - val_loss: 0.8121 - val_categorical_accuracy: 0.7937\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.3915 - categorical_accuracy: 0.8673 - val_loss: 0.7312 - val_categorical_accuracy: 0.8188\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3808 - categorical_accuracy: 0.8708 - val_loss: 0.7708 - val_categorical_accuracy: 0.8088\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3777 - categorical_accuracy: 0.8735 - val_loss: 0.7964 - val_categorical_accuracy: 0.8083\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.3710 - categorical_accuracy: 0.8765 - val_loss: 0.7775 - val_categorical_accuracy: 0.8054\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.3637 - categorical_accuracy: 0.8754 - val_loss: 0.7823 - val_categorical_accuracy: 0.8054\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.3547 - categorical_accuracy: 0.8798 - val_loss: 0.7795 - val_categorical_accuracy: 0.8200\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.3666 - categorical_accuracy: 0.8746 - val_loss: 0.7579 - val_categorical_accuracy: 0.8225\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.3550 - categorical_accuracy: 0.8804 - val_loss: 0.7677 - val_categorical_accuracy: 0.8233\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.3369 - categorical_accuracy: 0.8900 - val_loss: 0.7557 - val_categorical_accuracy: 0.8258\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.3322 - categorical_accuracy: 0.8908 - val_loss: 0.7385 - val_categorical_accuracy: 0.8221\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.3177 - categorical_accuracy: 0.8990 - val_loss: 0.7740 - val_categorical_accuracy: 0.8217\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 279us/step - loss: 0.3300 - categorical_accuracy: 0.8913 - val_loss: 0.7683 - val_categorical_accuracy: 0.8200\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.3414 - categorical_accuracy: 0.8842 - val_loss: 0.8191 - val_categorical_accuracy: 0.8100\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.3140 - categorical_accuracy: 0.9027 - val_loss: 0.7603 - val_categorical_accuracy: 0.8317\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.3147 - categorical_accuracy: 0.8954 - val_loss: 0.7688 - val_categorical_accuracy: 0.8092\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2977 - categorical_accuracy: 0.8965 - val_loss: 0.7886 - val_categorical_accuracy: 0.8117\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.3075 - categorical_accuracy: 0.9033 - val_loss: 0.8008 - val_categorical_accuracy: 0.8225\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3100 - categorical_accuracy: 0.9000 - val_loss: 0.7954 - val_categorical_accuracy: 0.8246\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2759 - categorical_accuracy: 0.9108 - val_loss: 0.7586 - val_categorical_accuracy: 0.8304\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3079 - categorical_accuracy: 0.8996 - val_loss: 0.7517 - val_categorical_accuracy: 0.8313\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2903 - categorical_accuracy: 0.9052 - val_loss: 0.7871 - val_categorical_accuracy: 0.8254\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2899 - categorical_accuracy: 0.9048 - val_loss: 0.7574 - val_categorical_accuracy: 0.8333\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2745 - categorical_accuracy: 0.9092 - val_loss: 0.7666 - val_categorical_accuracy: 0.8333\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2748 - categorical_accuracy: 0.9098 - val_loss: 0.7903 - val_categorical_accuracy: 0.8279\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2586 - categorical_accuracy: 0.9183 - val_loss: 0.7571 - val_categorical_accuracy: 0.8383\n",
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.2488 - categorical_accuracy: 0.9165 - val_loss: 0.7546 - val_categorical_accuracy: 0.8375\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.2583 - categorical_accuracy: 0.9185 - val_loss: 0.8354 - val_categorical_accuracy: 0.8192\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2543 - categorical_accuracy: 0.9194 - val_loss: 0.7750 - val_categorical_accuracy: 0.8250\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.2525 - categorical_accuracy: 0.9221 - val_loss: 0.7209 - val_categorical_accuracy: 0.8492\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.2545 - categorical_accuracy: 0.9173 - val_loss: 0.7840 - val_categorical_accuracy: 0.8367\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2560 - categorical_accuracy: 0.9196 - val_loss: 0.7668 - val_categorical_accuracy: 0.8204\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2455 - categorical_accuracy: 0.9190 - val_loss: 0.7889 - val_categorical_accuracy: 0.8358\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2402 - categorical_accuracy: 0.9160 - val_loss: 0.7696 - val_categorical_accuracy: 0.8404\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2528 - categorical_accuracy: 0.9160 - val_loss: 0.7725 - val_categorical_accuracy: 0.8346\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.2558 - categorical_accuracy: 0.9210 - val_loss: 0.7635 - val_categorical_accuracy: 0.8483\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2282 - categorical_accuracy: 0.9279 - val_loss: 0.7532 - val_categorical_accuracy: 0.8392\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2113 - categorical_accuracy: 0.9358 - val_loss: 0.7723 - val_categorical_accuracy: 0.8396\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.2227 - categorical_accuracy: 0.9296 - val_loss: 0.7828 - val_categorical_accuracy: 0.8413\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2195 - categorical_accuracy: 0.9335 - val_loss: 0.8019 - val_categorical_accuracy: 0.8450\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.2213 - categorical_accuracy: 0.9288 - val_loss: 0.7562 - val_categorical_accuracy: 0.8396\n",
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 275us/step - loss: 0.2212 - categorical_accuracy: 0.9304 - val_loss: 0.7994 - val_categorical_accuracy: 0.8387\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.2325 - categorical_accuracy: 0.9315 - val_loss: 0.7750 - val_categorical_accuracy: 0.8404\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.2155 - categorical_accuracy: 0.9312 - val_loss: 0.8010 - val_categorical_accuracy: 0.8425\n",
      "2400/2400 [==============================] - 1s 510us/step\n",
      "categorical_accuracy: 84.25%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 2s 491us/step - loss: 2.2254 - categorical_accuracy: 0.1465 - val_loss: 2.1680 - val_categorical_accuracy: 0.1796\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 2.0993 - categorical_accuracy: 0.1821 - val_loss: 1.9145 - val_categorical_accuracy: 0.2546\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 1.9413 - categorical_accuracy: 0.2573 - val_loss: 1.7121 - val_categorical_accuracy: 0.3708\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 1.7896 - categorical_accuracy: 0.3287 - val_loss: 1.5599 - val_categorical_accuracy: 0.4325\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 1.6462 - categorical_accuracy: 0.3892 - val_loss: 1.3850 - val_categorical_accuracy: 0.4867\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 273us/step - loss: 1.5809 - categorical_accuracy: 0.4067 - val_loss: 1.2662 - val_categorical_accuracy: 0.5392\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 1.4024 - categorical_accuracy: 0.4902 - val_loss: 1.2316 - val_categorical_accuracy: 0.5196\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 1.3488 - categorical_accuracy: 0.5158 - val_loss: 1.0698 - val_categorical_accuracy: 0.5988\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 1.2427 - categorical_accuracy: 0.5550 - val_loss: 0.9828 - val_categorical_accuracy: 0.6258\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 1.2017 - categorical_accuracy: 0.5694 - val_loss: 0.9027 - val_categorical_accuracy: 0.6788\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 1.1443 - categorical_accuracy: 0.5912 - val_loss: 0.8855 - val_categorical_accuracy: 0.6867\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 1.0710 - categorical_accuracy: 0.6198 - val_loss: 0.8247 - val_categorical_accuracy: 0.7217\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 1.0356 - categorical_accuracy: 0.6298 - val_loss: 0.8015 - val_categorical_accuracy: 0.7192\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.9883 - categorical_accuracy: 0.6519 - val_loss: 0.7836 - val_categorical_accuracy: 0.7175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.9617 - categorical_accuracy: 0.6644 - val_loss: 0.7830 - val_categorical_accuracy: 0.7296\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.9459 - categorical_accuracy: 0.6625 - val_loss: 0.7112 - val_categorical_accuracy: 0.7563\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.9005 - categorical_accuracy: 0.6935 - val_loss: 0.6921 - val_categorical_accuracy: 0.7554\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.8788 - categorical_accuracy: 0.7000 - val_loss: 0.7176 - val_categorical_accuracy: 0.7333\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.8495 - categorical_accuracy: 0.7123 - val_loss: 0.7027 - val_categorical_accuracy: 0.7479\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.8162 - categorical_accuracy: 0.7260 - val_loss: 0.6542 - val_categorical_accuracy: 0.7725\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.7945 - categorical_accuracy: 0.7296 - val_loss: 0.6352 - val_categorical_accuracy: 0.7708\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.7883 - categorical_accuracy: 0.7283 - val_loss: 0.6235 - val_categorical_accuracy: 0.7800\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.7449 - categorical_accuracy: 0.7535 - val_loss: 0.5684 - val_categorical_accuracy: 0.7983\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.7405 - categorical_accuracy: 0.7535 - val_loss: 0.5782 - val_categorical_accuracy: 0.7975\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.7169 - categorical_accuracy: 0.7525 - val_loss: 0.5732 - val_categorical_accuracy: 0.7921\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.6949 - categorical_accuracy: 0.7587 - val_loss: 0.5597 - val_categorical_accuracy: 0.8071\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.6769 - categorical_accuracy: 0.7727 - val_loss: 0.5926 - val_categorical_accuracy: 0.7888\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.6662 - categorical_accuracy: 0.7729 - val_loss: 0.5737 - val_categorical_accuracy: 0.7996\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.6380 - categorical_accuracy: 0.7810 - val_loss: 0.5269 - val_categorical_accuracy: 0.8125\n",
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6297 - categorical_accuracy: 0.7846 - val_loss: 0.5267 - val_categorical_accuracy: 0.8112\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.6279 - categorical_accuracy: 0.7860 - val_loss: 0.6178 - val_categorical_accuracy: 0.7779\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.6341 - categorical_accuracy: 0.7906 - val_loss: 0.4878 - val_categorical_accuracy: 0.8254\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 254us/step - loss: 0.6138 - categorical_accuracy: 0.7977 - val_loss: 0.4915 - val_categorical_accuracy: 0.8200\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6020 - categorical_accuracy: 0.7969 - val_loss: 0.4928 - val_categorical_accuracy: 0.8292\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.5823 - categorical_accuracy: 0.8012 - val_loss: 0.4755 - val_categorical_accuracy: 0.8308\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.5810 - categorical_accuracy: 0.8098 - val_loss: 0.4858 - val_categorical_accuracy: 0.8292\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.5510 - categorical_accuracy: 0.8173 - val_loss: 0.5298 - val_categorical_accuracy: 0.8154\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.5696 - categorical_accuracy: 0.8117 - val_loss: 0.4899 - val_categorical_accuracy: 0.8308\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.5501 - categorical_accuracy: 0.8183 - val_loss: 0.4742 - val_categorical_accuracy: 0.8250\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 275us/step - loss: 0.5491 - categorical_accuracy: 0.8171 - val_loss: 0.5142 - val_categorical_accuracy: 0.8154\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.5346 - categorical_accuracy: 0.8219 - val_loss: 0.4594 - val_categorical_accuracy: 0.8346\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 276us/step - loss: 0.5282 - categorical_accuracy: 0.8229 - val_loss: 0.4663 - val_categorical_accuracy: 0.8379\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.5271 - categorical_accuracy: 0.8271 - val_loss: 0.4734 - val_categorical_accuracy: 0.8325\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.5337 - categorical_accuracy: 0.8273 - val_loss: 0.4537 - val_categorical_accuracy: 0.8462\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 274us/step - loss: 0.5320 - categorical_accuracy: 0.8221 - val_loss: 0.4663 - val_categorical_accuracy: 0.8354\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.5094 - categorical_accuracy: 0.8319 - val_loss: 0.4394 - val_categorical_accuracy: 0.8512\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.4916 - categorical_accuracy: 0.8440 - val_loss: 0.4377 - val_categorical_accuracy: 0.8454\n",
      "Epoch 48/80\n",
      "4800/4800 [==============================] - 1s 282us/step - loss: 0.4889 - categorical_accuracy: 0.8350 - val_loss: 0.4347 - val_categorical_accuracy: 0.8517\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.4951 - categorical_accuracy: 0.8404 - val_loss: 0.4747 - val_categorical_accuracy: 0.8446\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.4756 - categorical_accuracy: 0.8431 - val_loss: 0.4665 - val_categorical_accuracy: 0.8529\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.4748 - categorical_accuracy: 0.8390 - val_loss: 0.4405 - val_categorical_accuracy: 0.8488\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.4613 - categorical_accuracy: 0.8508 - val_loss: 0.4571 - val_categorical_accuracy: 0.8388\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4594 - categorical_accuracy: 0.8446 - val_loss: 0.4278 - val_categorical_accuracy: 0.8500\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4519 - categorical_accuracy: 0.8523 - val_loss: 0.4407 - val_categorical_accuracy: 0.8488\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.4545 - categorical_accuracy: 0.8498 - val_loss: 0.4284 - val_categorical_accuracy: 0.8571\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.4509 - categorical_accuracy: 0.8504 - val_loss: 0.4548 - val_categorical_accuracy: 0.8475\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4526 - categorical_accuracy: 0.8483 - val_loss: 0.4272 - val_categorical_accuracy: 0.8525\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.4321 - categorical_accuracy: 0.8615 - val_loss: 0.3995 - val_categorical_accuracy: 0.8725\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.4305 - categorical_accuracy: 0.8602 - val_loss: 0.4103 - val_categorical_accuracy: 0.8583\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.4236 - categorical_accuracy: 0.8617 - val_loss: 0.4305 - val_categorical_accuracy: 0.8554\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.4252 - categorical_accuracy: 0.8587 - val_loss: 0.4300 - val_categorical_accuracy: 0.8504\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4048 - categorical_accuracy: 0.8690 - val_loss: 0.3781 - val_categorical_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.4026 - categorical_accuracy: 0.8690 - val_loss: 0.4155 - val_categorical_accuracy: 0.8633\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4029 - categorical_accuracy: 0.8738 - val_loss: 0.4375 - val_categorical_accuracy: 0.8625\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3933 - categorical_accuracy: 0.8690 - val_loss: 0.3974 - val_categorical_accuracy: 0.8750\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.4028 - categorical_accuracy: 0.8756 - val_loss: 0.4093 - val_categorical_accuracy: 0.8679\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.3930 - categorical_accuracy: 0.8692 - val_loss: 0.4063 - val_categorical_accuracy: 0.8688\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.3854 - categorical_accuracy: 0.8785 - val_loss: 0.4159 - val_categorical_accuracy: 0.8712\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.3852 - categorical_accuracy: 0.8754 - val_loss: 0.3998 - val_categorical_accuracy: 0.8733\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.3778 - categorical_accuracy: 0.8760 - val_loss: 0.4351 - val_categorical_accuracy: 0.8633\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3741 - categorical_accuracy: 0.8823 - val_loss: 0.4105 - val_categorical_accuracy: 0.8629\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.3723 - categorical_accuracy: 0.8804 - val_loss: 0.3971 - val_categorical_accuracy: 0.8742\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.3762 - categorical_accuracy: 0.8787 - val_loss: 0.4095 - val_categorical_accuracy: 0.8700\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.3691 - categorical_accuracy: 0.8840 - val_loss: 0.3790 - val_categorical_accuracy: 0.8758\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.3511 - categorical_accuracy: 0.8912 - val_loss: 0.3837 - val_categorical_accuracy: 0.8775\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 273us/step - loss: 0.3543 - categorical_accuracy: 0.8917 - val_loss: 0.3826 - val_categorical_accuracy: 0.8754\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 268us/step - loss: 0.3630 - categorical_accuracy: 0.8887 - val_loss: 0.3791 - val_categorical_accuracy: 0.8775\n",
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3700 - categorical_accuracy: 0.8798 - val_loss: 0.3778 - val_categorical_accuracy: 0.8771\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.3419 - categorical_accuracy: 0.8892 - val_loss: 0.3859 - val_categorical_accuracy: 0.8733\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.3439 - categorical_accuracy: 0.8898 - val_loss: 0.3822 - val_categorical_accuracy: 0.8821\n",
      "2400/2400 [==============================] - 1s 496us/step\n",
      "categorical_accuracy: 88.21%\n",
      "\n",
      "....................\n",
      "Cross validation fold [3]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/80\n",
      "4800/4800 [==============================] - 2s 514us/step - loss: 2.2680 - categorical_accuracy: 0.1271 - val_loss: 2.2073 - val_categorical_accuracy: 0.1575\n",
      "Epoch 2/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 2.1843 - categorical_accuracy: 0.1542 - val_loss: 2.0528 - val_categorical_accuracy: 0.2296\n",
      "Epoch 3/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 1.9982 - categorical_accuracy: 0.2429 - val_loss: 1.8905 - val_categorical_accuracy: 0.2637\n",
      "Epoch 4/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 1.8609 - categorical_accuracy: 0.2840 - val_loss: 1.7145 - val_categorical_accuracy: 0.3804\n",
      "Epoch 5/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 1.7627 - categorical_accuracy: 0.3385 - val_loss: 1.6457 - val_categorical_accuracy: 0.4262\n",
      "Epoch 6/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 1.6241 - categorical_accuracy: 0.3938 - val_loss: 1.5070 - val_categorical_accuracy: 0.4658\n",
      "Epoch 7/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 1.5002 - categorical_accuracy: 0.4408 - val_loss: 1.5101 - val_categorical_accuracy: 0.4404\n",
      "Epoch 8/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 1.4120 - categorical_accuracy: 0.4800 - val_loss: 1.3539 - val_categorical_accuracy: 0.5429\n",
      "Epoch 9/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 1.3057 - categorical_accuracy: 0.5317 - val_loss: 1.2908 - val_categorical_accuracy: 0.5642\n",
      "Epoch 10/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 1.2497 - categorical_accuracy: 0.5521 - val_loss: 1.1924 - val_categorical_accuracy: 0.5883\n",
      "Epoch 11/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 1.1544 - categorical_accuracy: 0.5881 - val_loss: 1.1319 - val_categorical_accuracy: 0.6258\n",
      "Epoch 12/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 1.0864 - categorical_accuracy: 0.6106 - val_loss: 1.0645 - val_categorical_accuracy: 0.6258\n",
      "Epoch 13/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 1.0268 - categorical_accuracy: 0.6337 - val_loss: 1.0132 - val_categorical_accuracy: 0.6500\n",
      "Epoch 14/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.9800 - categorical_accuracy: 0.6487 - val_loss: 1.0792 - val_categorical_accuracy: 0.6104\n",
      "Epoch 15/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.9190 - categorical_accuracy: 0.6762 - val_loss: 0.9750 - val_categorical_accuracy: 0.6704\n",
      "Epoch 16/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.8877 - categorical_accuracy: 0.6848 - val_loss: 0.9325 - val_categorical_accuracy: 0.6867\n",
      "Epoch 17/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.8492 - categorical_accuracy: 0.7010 - val_loss: 0.8782 - val_categorical_accuracy: 0.7033\n",
      "Epoch 18/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.8226 - categorical_accuracy: 0.7102 - val_loss: 0.8636 - val_categorical_accuracy: 0.7117\n",
      "Epoch 19/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.7972 - categorical_accuracy: 0.7223 - val_loss: 0.8644 - val_categorical_accuracy: 0.7088\n",
      "Epoch 20/80\n",
      "4800/4800 [==============================] - 1s 255us/step - loss: 0.7807 - categorical_accuracy: 0.7269 - val_loss: 0.8419 - val_categorical_accuracy: 0.7137\n",
      "Epoch 21/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.7423 - categorical_accuracy: 0.7429 - val_loss: 0.8205 - val_categorical_accuracy: 0.7296\n",
      "Epoch 22/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.7130 - categorical_accuracy: 0.7594 - val_loss: 0.9066 - val_categorical_accuracy: 0.7217\n",
      "Epoch 23/80\n",
      "4800/4800 [==============================] - 1s 253us/step - loss: 0.6969 - categorical_accuracy: 0.7602 - val_loss: 0.7792 - val_categorical_accuracy: 0.7504\n",
      "Epoch 24/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.6766 - categorical_accuracy: 0.7717 - val_loss: 0.7825 - val_categorical_accuracy: 0.7567\n",
      "Epoch 25/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.6717 - categorical_accuracy: 0.7725 - val_loss: 0.7526 - val_categorical_accuracy: 0.7567\n",
      "Epoch 26/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.6432 - categorical_accuracy: 0.7785 - val_loss: 0.7655 - val_categorical_accuracy: 0.7629\n",
      "Epoch 27/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.6348 - categorical_accuracy: 0.7896 - val_loss: 0.7533 - val_categorical_accuracy: 0.7592\n",
      "Epoch 28/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.6140 - categorical_accuracy: 0.7908 - val_loss: 0.7291 - val_categorical_accuracy: 0.7737\n",
      "Epoch 29/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.5999 - categorical_accuracy: 0.7946 - val_loss: 0.7300 - val_categorical_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.5726 - categorical_accuracy: 0.8031 - val_loss: 0.7534 - val_categorical_accuracy: 0.7713\n",
      "Epoch 31/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.5600 - categorical_accuracy: 0.8083 - val_loss: 0.7069 - val_categorical_accuracy: 0.7796\n",
      "Epoch 32/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.5389 - categorical_accuracy: 0.8212 - val_loss: 0.6787 - val_categorical_accuracy: 0.7833\n",
      "Epoch 33/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.5486 - categorical_accuracy: 0.8154 - val_loss: 0.6512 - val_categorical_accuracy: 0.7879\n",
      "Epoch 34/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.5441 - categorical_accuracy: 0.8217 - val_loss: 0.6837 - val_categorical_accuracy: 0.7758\n",
      "Epoch 35/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.5106 - categorical_accuracy: 0.8256 - val_loss: 0.6633 - val_categorical_accuracy: 0.7938\n",
      "Epoch 36/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.5073 - categorical_accuracy: 0.8233 - val_loss: 0.6608 - val_categorical_accuracy: 0.7917\n",
      "Epoch 37/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4919 - categorical_accuracy: 0.8296 - val_loss: 0.6797 - val_categorical_accuracy: 0.7921\n",
      "Epoch 38/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.4839 - categorical_accuracy: 0.8381 - val_loss: 0.6621 - val_categorical_accuracy: 0.7925\n",
      "Epoch 39/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.4768 - categorical_accuracy: 0.8440 - val_loss: 0.6455 - val_categorical_accuracy: 0.7917\n",
      "Epoch 40/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.4735 - categorical_accuracy: 0.8367 - val_loss: 0.6327 - val_categorical_accuracy: 0.8079\n",
      "Epoch 41/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.4617 - categorical_accuracy: 0.8444 - val_loss: 0.6432 - val_categorical_accuracy: 0.7942\n",
      "Epoch 42/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.4471 - categorical_accuracy: 0.8494 - val_loss: 0.6523 - val_categorical_accuracy: 0.8071\n",
      "Epoch 43/80\n",
      "4800/4800 [==============================] - 1s 257us/step - loss: 0.4352 - categorical_accuracy: 0.8500 - val_loss: 0.6680 - val_categorical_accuracy: 0.8000\n",
      "Epoch 44/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.4365 - categorical_accuracy: 0.8550 - val_loss: 0.6297 - val_categorical_accuracy: 0.8121\n",
      "Epoch 45/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.4175 - categorical_accuracy: 0.8606 - val_loss: 0.6501 - val_categorical_accuracy: 0.8079\n",
      "Epoch 46/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.4294 - categorical_accuracy: 0.8577 - val_loss: 0.6461 - val_categorical_accuracy: 0.8112\n",
      "Epoch 47/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.4067 - categorical_accuracy: 0.8619 - val_loss: 0.6310 - val_categorical_accuracy: 0.8058\n",
      "Epoch 48/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.4112 - categorical_accuracy: 0.8631 - val_loss: 0.6143 - val_categorical_accuracy: 0.8162\n",
      "Epoch 49/80\n",
      "4800/4800 [==============================] - 1s 270us/step - loss: 0.3912 - categorical_accuracy: 0.8727 - val_loss: 0.6242 - val_categorical_accuracy: 0.8183\n",
      "Epoch 50/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.3874 - categorical_accuracy: 0.8675 - val_loss: 0.6007 - val_categorical_accuracy: 0.8271\n",
      "Epoch 51/80\n",
      "4800/4800 [==============================] - 1s 272us/step - loss: 0.3642 - categorical_accuracy: 0.8746 - val_loss: 0.6149 - val_categorical_accuracy: 0.8171\n",
      "Epoch 52/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.3735 - categorical_accuracy: 0.8727 - val_loss: 0.6112 - val_categorical_accuracy: 0.8208\n",
      "Epoch 53/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.3678 - categorical_accuracy: 0.8750 - val_loss: 0.5990 - val_categorical_accuracy: 0.8167\n",
      "Epoch 54/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.3606 - categorical_accuracy: 0.8740 - val_loss: 0.6301 - val_categorical_accuracy: 0.8125\n",
      "Epoch 55/80\n",
      "4800/4800 [==============================] - 1s 278us/step - loss: 0.3520 - categorical_accuracy: 0.8817 - val_loss: 0.6107 - val_categorical_accuracy: 0.8233\n",
      "Epoch 56/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.3460 - categorical_accuracy: 0.8858 - val_loss: 0.6443 - val_categorical_accuracy: 0.8208\n",
      "Epoch 57/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.3416 - categorical_accuracy: 0.8906 - val_loss: 0.5901 - val_categorical_accuracy: 0.8329\n",
      "Epoch 58/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3362 - categorical_accuracy: 0.8867 - val_loss: 0.5888 - val_categorical_accuracy: 0.8358\n",
      "Epoch 59/80\n",
      "4800/4800 [==============================] - 1s 260us/step - loss: 0.3436 - categorical_accuracy: 0.8858 - val_loss: 0.6085 - val_categorical_accuracy: 0.8292\n",
      "Epoch 60/80\n",
      "4800/4800 [==============================] - 1s 258us/step - loss: 0.3170 - categorical_accuracy: 0.8927 - val_loss: 0.5835 - val_categorical_accuracy: 0.8250\n",
      "Epoch 61/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.3209 - categorical_accuracy: 0.8925 - val_loss: 0.6218 - val_categorical_accuracy: 0.8242\n",
      "Epoch 62/80\n",
      "4800/4800 [==============================] - 1s 256us/step - loss: 0.3217 - categorical_accuracy: 0.8917 - val_loss: 0.5871 - val_categorical_accuracy: 0.8367\n",
      "Epoch 63/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.3196 - categorical_accuracy: 0.8910 - val_loss: 0.6000 - val_categorical_accuracy: 0.8283\n",
      "Epoch 64/80\n",
      "4800/4800 [==============================] - 1s 265us/step - loss: 0.3095 - categorical_accuracy: 0.9000 - val_loss: 0.5979 - val_categorical_accuracy: 0.8287\n",
      "Epoch 65/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.3022 - categorical_accuracy: 0.8994 - val_loss: 0.5570 - val_categorical_accuracy: 0.8496\n",
      "Epoch 66/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.3088 - categorical_accuracy: 0.9021 - val_loss: 0.5548 - val_categorical_accuracy: 0.8396\n",
      "Epoch 67/80\n",
      "4800/4800 [==============================] - 1s 259us/step - loss: 0.2869 - categorical_accuracy: 0.9069 - val_loss: 0.6030 - val_categorical_accuracy: 0.8421\n",
      "Epoch 68/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.2959 - categorical_accuracy: 0.9000 - val_loss: 0.5662 - val_categorical_accuracy: 0.8450\n",
      "Epoch 69/80\n",
      "4800/4800 [==============================] - 1s 271us/step - loss: 0.2874 - categorical_accuracy: 0.9127 - val_loss: 0.5781 - val_categorical_accuracy: 0.8463\n",
      "Epoch 70/80\n",
      "4800/4800 [==============================] - 1s 266us/step - loss: 0.2771 - categorical_accuracy: 0.9073 - val_loss: 0.6032 - val_categorical_accuracy: 0.8450\n",
      "Epoch 71/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2693 - categorical_accuracy: 0.9125 - val_loss: 0.5799 - val_categorical_accuracy: 0.8438\n",
      "Epoch 72/80\n",
      "4800/4800 [==============================] - 1s 262us/step - loss: 0.2600 - categorical_accuracy: 0.9183 - val_loss: 0.5968 - val_categorical_accuracy: 0.8412\n",
      "Epoch 73/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.2597 - categorical_accuracy: 0.9154 - val_loss: 0.5530 - val_categorical_accuracy: 0.8488\n",
      "Epoch 74/80\n",
      "4800/4800 [==============================] - 1s 263us/step - loss: 0.3027 - categorical_accuracy: 0.9046 - val_loss: 0.6000 - val_categorical_accuracy: 0.8400\n",
      "Epoch 75/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.2720 - categorical_accuracy: 0.9138 - val_loss: 0.5940 - val_categorical_accuracy: 0.8446\n",
      "Epoch 76/80\n",
      "4800/4800 [==============================] - 1s 261us/step - loss: 0.2543 - categorical_accuracy: 0.9260 - val_loss: 0.6026 - val_categorical_accuracy: 0.8542\n",
      "Epoch 77/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.2542 - categorical_accuracy: 0.9204 - val_loss: 0.5882 - val_categorical_accuracy: 0.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80\n",
      "4800/4800 [==============================] - 1s 269us/step - loss: 0.2471 - categorical_accuracy: 0.9215 - val_loss: 0.5807 - val_categorical_accuracy: 0.8529\n",
      "Epoch 79/80\n",
      "4800/4800 [==============================] - 1s 267us/step - loss: 0.2397 - categorical_accuracy: 0.9221 - val_loss: 0.5804 - val_categorical_accuracy: 0.8525\n",
      "Epoch 80/80\n",
      "4800/4800 [==============================] - 1s 264us/step - loss: 0.2405 - categorical_accuracy: 0.9240 - val_loss: 0.6190 - val_categorical_accuracy: 0.8517\n",
      "2400/2400 [==============================] - 1s 503us/step\n",
      "categorical_accuracy: 85.17%\n",
      "85.88% (+/- 1.69%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84.25, 88.208333333333329, 85.166666666666671]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 80\n",
    "PARAM_BATCH_SIZE = 300\n",
    "\n",
    "from models.regularized_64_gru import Regularized64GRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = Regularized64GRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow the notebook to access the parent directory so we can import the other modules\n",
    "# https://stackoverflow.com/a/35273613\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Folder Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_folder_path = os.path.join(\"..\", \"files\", \"dataset\")\n",
    "NUM_SAMPLES = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Split into *Test*, *Train/Valid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DataSet import DataSet\n",
    "dataset = DataSet()\n",
    "# dataset.load(dataset_folder_path, test_set_percentage=0.3333, validation_set_percentage=0.3333)\n",
    "dataset.load(dataset_folder_path, test_set_percentage=0, validation_set_percentage=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train_data))\n",
    "print(len(dataset.test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import *\n",
    "from functools import partial\n",
    "dataset.apply(apply_mean_centering)\n",
    "dataset.apply(apply_unit_distance_normalization)\n",
    "#dataset.apply(partial(normalize_pressure_value, max_pressure_val=512))\n",
    "dataset.apply(partial(spline_interpolate_and_resample, num_samples=NUM_SAMPLES))\n",
    "dataset.expand(reverse_digit_sequence)\n",
    "# dataset.apply(lambda digit: convert_xy_to_derivative(digit, normalize=False))\n",
    "#dataset.apply(partial(convert_xy_to_derivative, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train_data))\n",
    "print(len(dataset.test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dataset, don't split, don't onehot encode, since we will perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = np.array(dataset.train_data)\n",
    "# X_valid = np.array(dataset.valid_data)\n",
    "# X_test = np.array(dataset.test_data)\n",
    "\n",
    "Y_train = np.array(dataset.train_labels)\n",
    "# Convert labels to numpy array and OneHot encode them\n",
    "# encoder, Y_train, Y_valid, Y_test = dataset.onehot_encode_labels()\n",
    "# Y_train = Y_train.astype('float32').todense()\n",
    "# Y_valid = Y_valid.astype('float32').todense()\n",
    "# Y_test = Y_test.astype('float32').todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# **Regularized Naive Deep GRU**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 897us/step - loss: 2.1520 - categorical_accuracy: 0.2025 - val_loss: 2.0329 - val_categorical_accuracy: 0.2250\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 677us/step - loss: 1.7538 - categorical_accuracy: 0.3471 - val_loss: 1.5116 - val_categorical_accuracy: 0.4921\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 1.2495 - categorical_accuracy: 0.5623 - val_loss: 1.1988 - val_categorical_accuracy: 0.6183\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 678us/step - loss: 0.8755 - categorical_accuracy: 0.7067 - val_loss: 0.7724 - val_categorical_accuracy: 0.7738\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.5751 - categorical_accuracy: 0.8146 - val_loss: 0.6025 - val_categorical_accuracy: 0.8279\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 683us/step - loss: 0.4613 - categorical_accuracy: 0.8535 - val_loss: 0.5363 - val_categorical_accuracy: 0.8463\n",
      "Epoch 7/40\n",
      "4800/4800 [==============================] - 3s 701us/step - loss: 0.3206 - categorical_accuracy: 0.9038 - val_loss: 0.4210 - val_categorical_accuracy: 0.8958\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 685us/step - loss: 0.2788 - categorical_accuracy: 0.9144 - val_loss: 0.3922 - val_categorical_accuracy: 0.8925\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.2150 - categorical_accuracy: 0.9338 - val_loss: 0.3082 - val_categorical_accuracy: 0.9242\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 705us/step - loss: 0.1751 - categorical_accuracy: 0.9506 - val_loss: 0.3382 - val_categorical_accuracy: 0.9054\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 689us/step - loss: 0.1516 - categorical_accuracy: 0.9590 - val_loss: 0.2898 - val_categorical_accuracy: 0.9271\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.1394 - categorical_accuracy: 0.9587 - val_loss: 0.2507 - val_categorical_accuracy: 0.9375\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.1133 - categorical_accuracy: 0.9696 - val_loss: 0.2382 - val_categorical_accuracy: 0.9442\n",
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 689us/step - loss: 0.0984 - categorical_accuracy: 0.9721 - val_loss: 0.2472 - val_categorical_accuracy: 0.9362\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 669us/step - loss: 0.1010 - categorical_accuracy: 0.9694 - val_loss: 0.2802 - val_categorical_accuracy: 0.9229\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 668us/step - loss: 0.0901 - categorical_accuracy: 0.9748 - val_loss: 0.2368 - val_categorical_accuracy: 0.9413\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.0857 - categorical_accuracy: 0.9763 - val_loss: 0.2219 - val_categorical_accuracy: 0.9463\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 718us/step - loss: 0.0680 - categorical_accuracy: 0.9821 - val_loss: 0.2265 - val_categorical_accuracy: 0.9417\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.0646 - categorical_accuracy: 0.9806 - val_loss: 0.2485 - val_categorical_accuracy: 0.9358\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 672us/step - loss: 0.0546 - categorical_accuracy: 0.9838 - val_loss: 0.2217 - val_categorical_accuracy: 0.9450\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 670us/step - loss: 0.0568 - categorical_accuracy: 0.9850 - val_loss: 0.2085 - val_categorical_accuracy: 0.9487\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 674us/step - loss: 0.0548 - categorical_accuracy: 0.9833 - val_loss: 0.1992 - val_categorical_accuracy: 0.9546\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 668us/step - loss: 0.0378 - categorical_accuracy: 0.9900 - val_loss: 0.2315 - val_categorical_accuracy: 0.9412\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 669us/step - loss: 0.0368 - categorical_accuracy: 0.9896 - val_loss: 0.2974 - val_categorical_accuracy: 0.9233\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 678us/step - loss: 0.0566 - categorical_accuracy: 0.9833 - val_loss: 0.2297 - val_categorical_accuracy: 0.9425\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 669us/step - loss: 0.0478 - categorical_accuracy: 0.9867 - val_loss: 0.2357 - val_categorical_accuracy: 0.9446\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 669us/step - loss: 0.0352 - categorical_accuracy: 0.9894 - val_loss: 0.2036 - val_categorical_accuracy: 0.9517\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 668us/step - loss: 0.0339 - categorical_accuracy: 0.9898 - val_loss: 0.2330 - val_categorical_accuracy: 0.9454\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 684us/step - loss: 0.0273 - categorical_accuracy: 0.9931 - val_loss: 0.2485 - val_categorical_accuracy: 0.9396\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 0.0324 - categorical_accuracy: 0.9908 - val_loss: 0.2064 - val_categorical_accuracy: 0.9513\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.0289 - categorical_accuracy: 0.9913 - val_loss: 0.2209 - val_categorical_accuracy: 0.9500\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 4s 733us/step - loss: 0.0346 - categorical_accuracy: 0.9883 - val_loss: 0.2197 - val_categorical_accuracy: 0.9446\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 709us/step - loss: 0.0329 - categorical_accuracy: 0.9904 - val_loss: 0.2195 - val_categorical_accuracy: 0.9471\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 685us/step - loss: 0.0274 - categorical_accuracy: 0.9925 - val_loss: 0.2141 - val_categorical_accuracy: 0.9508\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 729us/step - loss: 0.0198 - categorical_accuracy: 0.9958 - val_loss: 0.2327 - val_categorical_accuracy: 0.9442\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 698us/step - loss: 0.0340 - categorical_accuracy: 0.9908 - val_loss: 0.2667 - val_categorical_accuracy: 0.9433\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 704us/step - loss: 0.0218 - categorical_accuracy: 0.9942 - val_loss: 0.2293 - val_categorical_accuracy: 0.9483\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 707us/step - loss: 0.0237 - categorical_accuracy: 0.9931 - val_loss: 0.2488 - val_categorical_accuracy: 0.9458\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 691us/step - loss: 0.0209 - categorical_accuracy: 0.9948 - val_loss: 0.1989 - val_categorical_accuracy: 0.9500\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 689us/step - loss: 0.0167 - categorical_accuracy: 0.9960 - val_loss: 0.2202 - val_categorical_accuracy: 0.9500\n",
      "2400/2400 [==============================] - 1s 513us/step\n",
      "categorical_accuracy: 95.00%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 849us/step - loss: 2.1597 - categorical_accuracy: 0.1854 - val_loss: 1.8964 - val_categorical_accuracy: 0.2687\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 717us/step - loss: 1.7440 - categorical_accuracy: 0.3519 - val_loss: 1.5542 - val_categorical_accuracy: 0.4533\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 694us/step - loss: 1.3214 - categorical_accuracy: 0.5404 - val_loss: 1.0013 - val_categorical_accuracy: 0.7088\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.9615 - categorical_accuracy: 0.6860 - val_loss: 0.8032 - val_categorical_accuracy: 0.7379\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.7089 - categorical_accuracy: 0.7654 - val_loss: 0.5504 - val_categorical_accuracy: 0.8475\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 690us/step - loss: 0.4931 - categorical_accuracy: 0.8456 - val_loss: 0.4679 - val_categorical_accuracy: 0.8646\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 3s 683us/step - loss: 0.3555 - categorical_accuracy: 0.8927 - val_loss: 0.3581 - val_categorical_accuracy: 0.8983\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.2780 - categorical_accuracy: 0.9148 - val_loss: 0.3340 - val_categorical_accuracy: 0.9088\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 688us/step - loss: 0.2108 - categorical_accuracy: 0.9390 - val_loss: 0.2641 - val_categorical_accuracy: 0.9250\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.1749 - categorical_accuracy: 0.9523 - val_loss: 0.2594 - val_categorical_accuracy: 0.9271\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 689us/step - loss: 0.1432 - categorical_accuracy: 0.9623 - val_loss: 0.2361 - val_categorical_accuracy: 0.9317\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 691us/step - loss: 0.1326 - categorical_accuracy: 0.9635 - val_loss: 0.2262 - val_categorical_accuracy: 0.9354\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.1153 - categorical_accuracy: 0.9696 - val_loss: 0.2808 - val_categorical_accuracy: 0.9254\n",
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 4s 732us/step - loss: 0.0911 - categorical_accuracy: 0.9769 - val_loss: 0.2560 - val_categorical_accuracy: 0.9354\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.0877 - categorical_accuracy: 0.9760 - val_loss: 0.2374 - val_categorical_accuracy: 0.9388\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 695us/step - loss: 0.0747 - categorical_accuracy: 0.9796 - val_loss: 0.2677 - val_categorical_accuracy: 0.9337\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.0692 - categorical_accuracy: 0.9821 - val_loss: 0.2538 - val_categorical_accuracy: 0.9404\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 698us/step - loss: 0.0649 - categorical_accuracy: 0.9819 - val_loss: 0.2178 - val_categorical_accuracy: 0.9488\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.0575 - categorical_accuracy: 0.9865 - val_loss: 0.2421 - val_categorical_accuracy: 0.9396\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 698us/step - loss: 0.0488 - categorical_accuracy: 0.9869 - val_loss: 0.2362 - val_categorical_accuracy: 0.9421\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 701us/step - loss: 0.0454 - categorical_accuracy: 0.9875 - val_loss: 0.2757 - val_categorical_accuracy: 0.9354\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 711us/step - loss: 0.0416 - categorical_accuracy: 0.9894 - val_loss: 0.2350 - val_categorical_accuracy: 0.9463\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 705us/step - loss: 0.0333 - categorical_accuracy: 0.9925 - val_loss: 0.2463 - val_categorical_accuracy: 0.9433\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 0.0347 - categorical_accuracy: 0.9902 - val_loss: 0.2514 - val_categorical_accuracy: 0.9425\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 0.0336 - categorical_accuracy: 0.9900 - val_loss: 0.2586 - val_categorical_accuracy: 0.9413\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 714us/step - loss: 0.0279 - categorical_accuracy: 0.9933 - val_loss: 0.2629 - val_categorical_accuracy: 0.9438\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.0316 - categorical_accuracy: 0.9921 - val_loss: 0.2485 - val_categorical_accuracy: 0.9479\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 706us/step - loss: 0.0265 - categorical_accuracy: 0.9933 - val_loss: 0.2744 - val_categorical_accuracy: 0.9475\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 705us/step - loss: 0.0269 - categorical_accuracy: 0.9927 - val_loss: 0.3057 - val_categorical_accuracy: 0.9329\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 714us/step - loss: 0.0218 - categorical_accuracy: 0.9944 - val_loss: 0.2595 - val_categorical_accuracy: 0.9396\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 701us/step - loss: 0.0184 - categorical_accuracy: 0.9958 - val_loss: 0.2665 - val_categorical_accuracy: 0.9438\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.0182 - categorical_accuracy: 0.9950 - val_loss: 0.2897 - val_categorical_accuracy: 0.9412\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 702us/step - loss: 0.0147 - categorical_accuracy: 0.9969 - val_loss: 0.2640 - val_categorical_accuracy: 0.9492\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 701us/step - loss: 0.0165 - categorical_accuracy: 0.9958 - val_loss: 0.2819 - val_categorical_accuracy: 0.9408\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 695us/step - loss: 0.0122 - categorical_accuracy: 0.9969 - val_loss: 0.2925 - val_categorical_accuracy: 0.9450\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 690us/step - loss: 0.0226 - categorical_accuracy: 0.9948 - val_loss: 0.2784 - val_categorical_accuracy: 0.9442\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 688us/step - loss: 0.0186 - categorical_accuracy: 0.9946 - val_loss: 0.2552 - val_categorical_accuracy: 0.9508\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 692us/step - loss: 0.0142 - categorical_accuracy: 0.9969 - val_loss: 0.2773 - val_categorical_accuracy: 0.9417\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 693us/step - loss: 0.0178 - categorical_accuracy: 0.9958 - val_loss: 0.2578 - val_categorical_accuracy: 0.9529\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 690us/step - loss: 0.0100 - categorical_accuracy: 0.9977 - val_loss: 0.2448 - val_categorical_accuracy: 0.9525\n",
      "2400/2400 [==============================] - 1s 506us/step\n",
      "categorical_accuracy: 95.25%\n",
      "\n",
      "....................\n",
      "Cross validation fold [3]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 871us/step - loss: 2.1338 - categorical_accuracy: 0.1958 - val_loss: 1.9621 - val_categorical_accuracy: 0.2562\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 1.7123 - categorical_accuracy: 0.3588 - val_loss: 1.5095 - val_categorical_accuracy: 0.4442\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 1.2808 - categorical_accuracy: 0.5458 - val_loss: 1.0724 - val_categorical_accuracy: 0.6408\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 679us/step - loss: 0.9269 - categorical_accuracy: 0.6935 - val_loss: 0.7954 - val_categorical_accuracy: 0.7525\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.6091 - categorical_accuracy: 0.8075 - val_loss: 0.6345 - val_categorical_accuracy: 0.8138\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.4455 - categorical_accuracy: 0.8606 - val_loss: 0.6760 - val_categorical_accuracy: 0.7958\n",
      "Epoch 7/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.3032 - categorical_accuracy: 0.9100 - val_loss: 0.5284 - val_categorical_accuracy: 0.8392\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 680us/step - loss: 0.2279 - categorical_accuracy: 0.9346 - val_loss: 0.4217 - val_categorical_accuracy: 0.8821\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.1864 - categorical_accuracy: 0.9456 - val_loss: 0.4303 - val_categorical_accuracy: 0.8754\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.1423 - categorical_accuracy: 0.9621 - val_loss: 0.4186 - val_categorical_accuracy: 0.8858\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.1227 - categorical_accuracy: 0.9667 - val_loss: 0.4273 - val_categorical_accuracy: 0.8887\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.1100 - categorical_accuracy: 0.9698 - val_loss: 0.4117 - val_categorical_accuracy: 0.9012\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.0910 - categorical_accuracy: 0.9767 - val_loss: 0.4045 - val_categorical_accuracy: 0.8992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 673us/step - loss: 0.0802 - categorical_accuracy: 0.9806 - val_loss: 0.3810 - val_categorical_accuracy: 0.9037\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 670us/step - loss: 0.0784 - categorical_accuracy: 0.9788 - val_loss: 0.3723 - val_categorical_accuracy: 0.9083\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 671us/step - loss: 0.0638 - categorical_accuracy: 0.9844 - val_loss: 0.3785 - val_categorical_accuracy: 0.9050\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 671us/step - loss: 0.0681 - categorical_accuracy: 0.9835 - val_loss: 0.3618 - val_categorical_accuracy: 0.9117\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 673us/step - loss: 0.0632 - categorical_accuracy: 0.9817 - val_loss: 0.3760 - val_categorical_accuracy: 0.9108\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 697us/step - loss: 0.0526 - categorical_accuracy: 0.9869 - val_loss: 0.4071 - val_categorical_accuracy: 0.9075\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 700us/step - loss: 0.0478 - categorical_accuracy: 0.9881 - val_loss: 0.4076 - val_categorical_accuracy: 0.9096\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 703us/step - loss: 0.0412 - categorical_accuracy: 0.9900 - val_loss: 0.3887 - val_categorical_accuracy: 0.9133\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.0393 - categorical_accuracy: 0.9913 - val_loss: 0.3991 - val_categorical_accuracy: 0.9117\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 683us/step - loss: 0.0368 - categorical_accuracy: 0.9915 - val_loss: 0.3989 - val_categorical_accuracy: 0.9112\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 685us/step - loss: 0.0345 - categorical_accuracy: 0.9913 - val_loss: 0.4056 - val_categorical_accuracy: 0.9125\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 687us/step - loss: 0.0427 - categorical_accuracy: 0.9890 - val_loss: 0.3699 - val_categorical_accuracy: 0.9158\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 706us/step - loss: 0.0324 - categorical_accuracy: 0.9917 - val_loss: 0.4009 - val_categorical_accuracy: 0.9129\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 697us/step - loss: 0.0329 - categorical_accuracy: 0.9927 - val_loss: 0.3584 - val_categorical_accuracy: 0.9221\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 693us/step - loss: 0.0261 - categorical_accuracy: 0.9942 - val_loss: 0.3559 - val_categorical_accuracy: 0.9225\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 693us/step - loss: 0.0216 - categorical_accuracy: 0.9960 - val_loss: 0.3881 - val_categorical_accuracy: 0.9200\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 694us/step - loss: 0.0235 - categorical_accuracy: 0.9948 - val_loss: 0.3845 - val_categorical_accuracy: 0.9167\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 696us/step - loss: 0.0198 - categorical_accuracy: 0.9965 - val_loss: 0.3717 - val_categorical_accuracy: 0.9233\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 691us/step - loss: 0.0149 - categorical_accuracy: 0.9969 - val_loss: 0.3876 - val_categorical_accuracy: 0.9187\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.0165 - categorical_accuracy: 0.9965 - val_loss: 0.4738 - val_categorical_accuracy: 0.9058\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 681us/step - loss: 0.0207 - categorical_accuracy: 0.9954 - val_loss: 0.4019 - val_categorical_accuracy: 0.9208\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.0132 - categorical_accuracy: 0.9975 - val_loss: 0.4542 - val_categorical_accuracy: 0.9138\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 682us/step - loss: 0.0158 - categorical_accuracy: 0.9965 - val_loss: 0.3846 - val_categorical_accuracy: 0.9279\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 714us/step - loss: 0.0302 - categorical_accuracy: 0.9917 - val_loss: 0.4422 - val_categorical_accuracy: 0.9067\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 699us/step - loss: 0.0294 - categorical_accuracy: 0.9915 - val_loss: 0.4053 - val_categorical_accuracy: 0.9142\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 700us/step - loss: 0.0155 - categorical_accuracy: 0.9967 - val_loss: 0.3650 - val_categorical_accuracy: 0.9246\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 715us/step - loss: 0.0156 - categorical_accuracy: 0.9963 - val_loss: 0.4547 - val_categorical_accuracy: 0.9125\n",
      "2400/2400 [==============================] - 1s 507us/step\n",
      "categorical_accuracy: 91.25%\n",
      "93.83% (+/- 1.83%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[95.0, 95.25, 91.25]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 40\n",
    "PARAM_BATCH_SIZE = 300\n",
    "\n",
    "from models.regularized_deep_gru import NaiveRegularizedDeepGRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = NaiveRegularizedDeepGRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### increased batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................\n",
      "Cross validation fold [1]\n",
      "....................\n",
      "\n",
      "Train on 4800 samples, validate on 2400 samples\n",
      "Epoch 1/40\n",
      "4800/4800 [==============================] - 4s 766us/step - loss: 2.2194 - categorical_accuracy: 0.1829 - val_loss: 2.1009 - val_categorical_accuracy: 0.2496\n",
      "Epoch 2/40\n",
      "4800/4800 [==============================] - 3s 582us/step - loss: 2.0138 - categorical_accuracy: 0.2492 - val_loss: 1.8176 - val_categorical_accuracy: 0.3242\n",
      "Epoch 3/40\n",
      "4800/4800 [==============================] - 3s 563us/step - loss: 1.6939 - categorical_accuracy: 0.3723 - val_loss: 1.5784 - val_categorical_accuracy: 0.4204\n",
      "Epoch 4/40\n",
      "4800/4800 [==============================] - 3s 615us/step - loss: 1.4508 - categorical_accuracy: 0.4773 - val_loss: 1.3909 - val_categorical_accuracy: 0.4958\n",
      "Epoch 5/40\n",
      "4800/4800 [==============================] - 3s 571us/step - loss: 1.1906 - categorical_accuracy: 0.5783 - val_loss: 1.0936 - val_categorical_accuracy: 0.6638\n",
      "Epoch 6/40\n",
      "4800/4800 [==============================] - 3s 570us/step - loss: 1.0385 - categorical_accuracy: 0.6521 - val_loss: 0.9445 - val_categorical_accuracy: 0.7112\n",
      "Epoch 7/40\n",
      "4800/4800 [==============================] - 3s 569us/step - loss: 0.8065 - categorical_accuracy: 0.7483 - val_loss: 0.8591 - val_categorical_accuracy: 0.7375\n",
      "Epoch 8/40\n",
      "4800/4800 [==============================] - 3s 595us/step - loss: 0.6718 - categorical_accuracy: 0.7915 - val_loss: 0.7751 - val_categorical_accuracy: 0.7496\n",
      "Epoch 9/40\n",
      "4800/4800 [==============================] - 3s 574us/step - loss: 0.5490 - categorical_accuracy: 0.8306 - val_loss: 0.6513 - val_categorical_accuracy: 0.8054\n",
      "Epoch 10/40\n",
      "4800/4800 [==============================] - 3s 574us/step - loss: 0.5206 - categorical_accuracy: 0.8375 - val_loss: 0.5733 - val_categorical_accuracy: 0.8242\n",
      "Epoch 11/40\n",
      "4800/4800 [==============================] - 3s 575us/step - loss: 0.3921 - categorical_accuracy: 0.8875 - val_loss: 0.4425 - val_categorical_accuracy: 0.8671\n",
      "Epoch 12/40\n",
      "4800/4800 [==============================] - 3s 608us/step - loss: 0.3249 - categorical_accuracy: 0.9062 - val_loss: 0.5118 - val_categorical_accuracy: 0.8400\n",
      "Epoch 13/40\n",
      "4800/4800 [==============================] - 3s 578us/step - loss: 0.3107 - categorical_accuracy: 0.9060 - val_loss: 0.4263 - val_categorical_accuracy: 0.8825\n",
      "Epoch 14/40\n",
      "4800/4800 [==============================] - 3s 578us/step - loss: 0.2756 - categorical_accuracy: 0.9229 - val_loss: 0.3701 - val_categorical_accuracy: 0.8854\n",
      "Epoch 15/40\n",
      "4800/4800 [==============================] - 3s 602us/step - loss: 0.2396 - categorical_accuracy: 0.9285 - val_loss: 0.3651 - val_categorical_accuracy: 0.8958\n",
      "Epoch 16/40\n",
      "4800/4800 [==============================] - 3s 583us/step - loss: 0.2945 - categorical_accuracy: 0.9129 - val_loss: 0.3539 - val_categorical_accuracy: 0.9012\n",
      "Epoch 17/40\n",
      "4800/4800 [==============================] - 3s 586us/step - loss: 0.2066 - categorical_accuracy: 0.9398 - val_loss: 0.3295 - val_categorical_accuracy: 0.9046\n",
      "Epoch 18/40\n",
      "4800/4800 [==============================] - 3s 578us/step - loss: 0.1818 - categorical_accuracy: 0.9512 - val_loss: 0.3216 - val_categorical_accuracy: 0.9050\n",
      "Epoch 19/40\n",
      "4800/4800 [==============================] - 3s 599us/step - loss: 0.1676 - categorical_accuracy: 0.9506 - val_loss: 0.3003 - val_categorical_accuracy: 0.9142\n",
      "Epoch 20/40\n",
      "4800/4800 [==============================] - 3s 581us/step - loss: 0.1544 - categorical_accuracy: 0.9604 - val_loss: 0.2860 - val_categorical_accuracy: 0.9192\n",
      "Epoch 21/40\n",
      "4800/4800 [==============================] - 3s 580us/step - loss: 0.1484 - categorical_accuracy: 0.9573 - val_loss: 0.2803 - val_categorical_accuracy: 0.9204\n",
      "Epoch 22/40\n",
      "4800/4800 [==============================] - 3s 603us/step - loss: 0.1292 - categorical_accuracy: 0.9675 - val_loss: 0.2852 - val_categorical_accuracy: 0.9204\n",
      "Epoch 23/40\n",
      "4800/4800 [==============================] - 3s 593us/step - loss: 0.1201 - categorical_accuracy: 0.9663 - val_loss: 0.2931 - val_categorical_accuracy: 0.9225\n",
      "Epoch 24/40\n",
      "4800/4800 [==============================] - 3s 589us/step - loss: 0.1093 - categorical_accuracy: 0.9715 - val_loss: 0.2919 - val_categorical_accuracy: 0.9258\n",
      "Epoch 25/40\n",
      "4800/4800 [==============================] - 3s 639us/step - loss: 0.1141 - categorical_accuracy: 0.9683 - val_loss: 0.3070 - val_categorical_accuracy: 0.9196\n",
      "Epoch 26/40\n",
      "4800/4800 [==============================] - 3s 583us/step - loss: 0.0919 - categorical_accuracy: 0.9767 - val_loss: 0.3336 - val_categorical_accuracy: 0.9150\n",
      "Epoch 27/40\n",
      "4800/4800 [==============================] - 3s 582us/step - loss: 0.0935 - categorical_accuracy: 0.9758 - val_loss: 0.2943 - val_categorical_accuracy: 0.9246\n",
      "Epoch 28/40\n",
      "4800/4800 [==============================] - 3s 595us/step - loss: 0.0816 - categorical_accuracy: 0.9785 - val_loss: 0.2848 - val_categorical_accuracy: 0.9283\n",
      "Epoch 29/40\n",
      "4800/4800 [==============================] - 3s 581us/step - loss: 0.0814 - categorical_accuracy: 0.9773 - val_loss: 0.3049 - val_categorical_accuracy: 0.9238\n",
      "Epoch 30/40\n",
      "4800/4800 [==============================] - 3s 597us/step - loss: 0.0744 - categorical_accuracy: 0.9808 - val_loss: 0.2921 - val_categorical_accuracy: 0.9283\n",
      "Epoch 31/40\n",
      "4800/4800 [==============================] - 3s 589us/step - loss: 0.0668 - categorical_accuracy: 0.9819 - val_loss: 0.3334 - val_categorical_accuracy: 0.9246\n",
      "Epoch 32/40\n",
      "4800/4800 [==============================] - 3s 577us/step - loss: 0.0629 - categorical_accuracy: 0.9825 - val_loss: 0.2768 - val_categorical_accuracy: 0.9350\n",
      "Epoch 33/40\n",
      "4800/4800 [==============================] - 3s 585us/step - loss: 0.0557 - categorical_accuracy: 0.9867 - val_loss: 0.2870 - val_categorical_accuracy: 0.9292\n",
      "Epoch 34/40\n",
      "4800/4800 [==============================] - 3s 573us/step - loss: 0.0530 - categorical_accuracy: 0.9873 - val_loss: 0.3112 - val_categorical_accuracy: 0.9275\n",
      "Epoch 35/40\n",
      "4800/4800 [==============================] - 3s 572us/step - loss: 0.0512 - categorical_accuracy: 0.9875 - val_loss: 0.3080 - val_categorical_accuracy: 0.9267\n",
      "Epoch 36/40\n",
      "4800/4800 [==============================] - 3s 570us/step - loss: 0.0477 - categorical_accuracy: 0.9865 - val_loss: 0.2963 - val_categorical_accuracy: 0.9321\n",
      "Epoch 37/40\n",
      "4800/4800 [==============================] - 3s 572us/step - loss: 0.0454 - categorical_accuracy: 0.9892 - val_loss: 0.3307 - val_categorical_accuracy: 0.9275\n",
      "Epoch 38/40\n",
      "4800/4800 [==============================] - 3s 576us/step - loss: 0.0423 - categorical_accuracy: 0.9890 - val_loss: 0.3064 - val_categorical_accuracy: 0.9304\n",
      "Epoch 39/40\n",
      "4800/4800 [==============================] - 3s 581us/step - loss: 0.0632 - categorical_accuracy: 0.9825 - val_loss: 0.2873 - val_categorical_accuracy: 0.9329\n",
      "Epoch 40/40\n",
      "4800/4800 [==============================] - 3s 575us/step - loss: 0.0415 - categorical_accuracy: 0.9883 - val_loss: 0.2993 - val_categorical_accuracy: 0.9321\n",
      "2400/2400 [==============================] - 1s 493us/step\n",
      "categorical_accuracy: 93.21%\n",
      "\n",
      "....................\n",
      "Cross validation fold [2]\n",
      "....................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PARAM_NUM_EPOCHS = 40\n",
    "PARAM_BATCH_SIZE = 600\n",
    "\n",
    "from models.regularized_deep_gru import NaiveRegularizedDeepGRU\n",
    "from utils.evaluation import cross_validate_model\n",
    "\n",
    "mymodel = NaiveRegularizedDeepGRU(X_train.shape[1:])\n",
    "mymodel.batch_size = PARAM_BATCH_SIZE\n",
    "mymodel.num_epochs = PARAM_NUM_EPOCHS\n",
    "\n",
    "cross_validate_model(X_train, Y_train, mymodel, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
